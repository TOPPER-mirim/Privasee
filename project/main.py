from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import uvicorn
import re
import logging
from typing import List, Dict, Optional
from datetime import datetime
from collections import Counter
import os
import base64
import json
import google.generativeai as genai
import google.generativeai as genai
from PIL import Image


# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Gemini API ì„¤ì •

GEMINI_API_KEY = "AIzaSyAVn3vJk49bpx_q2wAUu7xvD2aMjpChbcg"  # ì‹¤ì œ í‚¤ë¡œ êµì²´
genai.configure(api_key=GEMINI_API_KEY)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(title="Gemini ê¸°ë°˜ ê°œì¸ì •ë³´ ìœ„í—˜ ìê°€ ì§„ë‹¨ ì„œë¹„ìŠ¤")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
class TextAnalysisRequest(BaseModel):
    text: str
    user_context: Optional[Dict] = None

class AnalysisResponse(BaseModel):
    risk_score: int
    detected_items: List[Dict]
    combination_risks: List[Dict]
    recommendations: List[str]
    personalized_feedback: str
    risk_level: str
    detailed_analysis: Optional[Dict] = None

# ê°œì¸ì •ë³´ íŒ¨í„´ ì •ì˜ (ì •ê·œì‹)
PATTERNS = {
    # ì „í™”ë²ˆí˜¸ (ë” ìœ ì—°í•œ íŒ¨í„´) - ìˆ˜ì •ë¨
    'phone': r'0(?:1[016789]|2|[3-6]\d|70)[-.\s]?\d{3,4}[-.\s]?\d{4}',
    'phone_international': r'\+\d{1,3}[-.\s]?\(?\d{1,4}\)?[-.\s]?\d{3,4}[-.\s]?\d{3,4}',
    
    # ì´ë©”ì¼
    'email': r'\b[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}\b',
    
    # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ (ë” ìœ ì—°í•œ íŒ¨í„´)
    'rrn': r'\b(?:19|20)?\d{2}(?:0[1-9]|1[0-2])(?:0[1-9]|[12]\d|3[01])[-\s]?[1-4]\d{6}\b',
    'rrn_partial': r'\b(?:19|20)\d{2}(?:0[1-9]|1[0-2])(?:0[1-9]|[12]\d|3[01])[-\s]?[*]{6}\b',  # ë’·ìë¦¬ ë§ˆìŠ¤í‚¹ëœ ê²½ìš°
    
    # ì—¬ê¶Œë²ˆí˜¸
    'passport': r'\b[A-Z]\d{7,8}\b',
    'passport_mrz': r'\b[A-Z0-9<]{20,}\b',
    
    # ìš´ì „ë©´í—ˆë²ˆí˜¸
    'driver_license': r'\b[0-9]{2}[-\s]?[0-9]{2}[-\s]?[0-9]{6}[-\s]?[0-9]{2}\b',
    
    # ì‹ ìš©ì¹´ë“œë²ˆí˜¸
    'credit_card': r'\b(?:\d{4}[-\s]?){3}\d{4}\b',
    'credit_card_partial': r'\b\d{4}[-\s]?[*]{4}[-\s]?[*]{4}[-\s]?\d{4}\b',  # ì¼ë¶€ ë§ˆìŠ¤í‚¹ëœ ê²½ìš°
    
    # ê³„ì¢Œë²ˆí˜¸
    'account': r'\b(?!0(?:1[016789]|2|[3-6]\d|70)[-.\s]?\d{3,4}[-.\s]?\d{4})\d{3,6}[-\s]?\d{2,6}[-\s]?\d{4,}\b',
    
    # ì£¼ì†Œ ê´€ë ¨ (ì„¸ë¶„í™”)
    # 1. ì‹œ/ë„ ë‹¨ìœ„
    'address_province': r'\b(?:ì„œìš¸|ë¶€ì‚°|ëŒ€êµ¬|ì¸ì²œ|ê´‘ì£¼|ëŒ€ì „|ìš¸ì‚°|ì„¸ì¢…|ê²½ê¸°|ê°•ì›|ì¶©ë¶|ì¶©ë‚¨|ì „ë¶|ì „ë‚¨|ê²½ë¶|ê²½ë‚¨|ì œì£¼)(?:íŠ¹ë³„ì‹œ|ê´‘ì—­ì‹œ|ë„|ì‹œ)?\b',
    
    # 2. ì‹œ/êµ°/êµ¬ ë‹¨ìœ„
    'address_city': r'\b[ê°€-í£]{2,}(?:ì‹œ|êµ°|êµ¬)\b',
    
    # 3. ì/ë©´/ë™/ë¦¬ ë‹¨ìœ„
    'address_district': r'\b[ê°€-í£0-9]{2,}(?:ì|ë©´|ë™|ë¦¬|ê°€)\b',
    
    # 4. ë„ë¡œëª… ì£¼ì†Œ
    'address_road': r'\b[ê°€-í£0-9]{2,}(?:ë¡œ|ê¸¸)\s*\d{1,5}(?:[-]\d{1,4})?\b',
    
    # 5. ì§€ë²ˆ ì£¼ì†Œ
    'address_jibun': r'\b[ê°€-í£0-9]{2,}ë™\s*\d{1,5}(?:[-]\d{1,5})?\b',
    
    # 6. ìƒì„¸ ì£¼ì†Œ (ê±´ë¬¼, í˜¸ìˆ˜ ë“±)
    'address_detail': r'\b\d{1,5}(?:[-]\d{1,4})?\s*(?:ë²ˆì§€|í˜¸|ì¸µ|ë™)\b',
    
    # 7. ìš°í¸ë²ˆí˜¸
    'postal_code': r'\b\d{5}\b',
    
    # í•™êµëª… (ë” ì„¸ë°€í•œ íŒ¨í„´)
    'school_elementary': r'\b[A-Za-zê°€-í£0-9\s\-]{2,40}(?:ì´ˆë“±í•™êµ|ì´ˆ)\b',
    'school_middle': r'\b[A-Za-zê°€-í£0-9\s\-]{2,40}(?:ì¤‘í•™êµ|ì¤‘)\b',
    'school_high': r'\b[A-Za-zê°€-í£0-9\s\-]{2,40}(?:ê³ ë“±í•™êµ|ê³ )\b',
    'school_university': r'\b[A-Za-zê°€-í£0-9\s\-]{2,40}(?:ëŒ€í•™êµ|ëŒ€í•™)\b',
    
    # ì§ì¥/ê¸°ê´€ëª… (ë” ì„¸ë°€í•œ íŒ¨í„´)
    'workplace_company': r'\b[A-Za-zê°€-í£0-9\s\-]{2,40}(?:íšŒì‚¬|ê¸°ì—…|ê·¸ë£¹|ì½”í¼ë ˆì´ì…˜|ì£¼ì‹íšŒì‚¬|ìœ í•œíšŒì‚¬)\b',
    'workplace_hospital': r'\b[A-Za-zê°€-í£0-9\s\-]{2,40}(?:ë³‘ì›|ì˜ì›|í•œì˜ì›|í´ë¦¬ë‹‰)\b',
    'workplace_bank': r'\b[A-Za-zê°€-í£0-9\s\-]{2,40}ì€í–‰\b',
    'workplace_public': r'\b[A-Za-zê°€-í£0-9\s\-]{2,40}(?:ì²­|ë¶€|ì²˜|ì›|ê³µì‚¬|ì„¼í„°)\b',
    
    # ì´ë¦„ (ë” ì—„ê²©í•˜ê²Œ - í˜¸ì¹­ì´ ìˆëŠ” ê²½ìš°ë§Œ)
    'name_with_title': r'(?<![A-Za-z0-9ê°€-í£])[ê°€-í£]{2,4}\s*(?:ë‹˜|ì”¨|êµ°|ì–‘|ì„ ìƒë‹˜|êµìˆ˜ë‹˜|ë°•ì‚¬ë‹˜|ë¶€ì¥ë‹˜|ê³¼ì¥ë‹˜|ëŒ€ë¦¬ë‹˜|ì‚¬ì›ë‹˜|ëŒ€í‘œë‹˜|íšŒì¥ë‹˜|ì‚¬ì¥ë‹˜)\b',
    
    # ìƒë…„ì›”ì¼ (ë” ë‹¤ì–‘í•œ í˜•ì‹)
    'birth_date': r'\b(?:19|20)\d{2}[ë…„\.\-/]\s?\d{1,2}[ì›”\.\-/]\s?\d{1,2}ì¼?\b',
    'birth_date_short': r'\b\d{2}[ë…„\.\-/]\s?\d{1,2}[ì›”\.\-/]\s?\d{1,2}ì¼?\b',
    'birth_date_numeric': r'\b(?:19|20)\d{2}[.\-/]\d{2}[.\-/]\d{2}\b',
    
    # ì°¨ëŸ‰ë²ˆí˜¸
    'car_number': r'\b\d{2,3}\s*[ê°€-í£]\s*\d{4}\b',
    
    # IP ì£¼ì†Œ
    'ip_address': r'\b(?:(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\.){3}(?:25[0-5]|2[0-4][0-9]|[01]?[0-9][0-9]?)\b',
    'ip_address_v6': r'\b(?:[0-9a-fA-F]{1,4}:){7}[0-9a-fA-F]{1,4}\b',
    
    # ì¶”ê°€ íŒ¨í„´ë“¤
    # ê±´ë¬¼ëª…
    'building_name': r'\b[ê°€-í£0-9\s\-]{2,40}(?:ì•„íŒŒíŠ¸|ë¹Œë¼|ì˜¤í”¼ìŠ¤í…”|ì£¼ìƒë³µí•©|íƒ€ì›Œ|ë¹Œë”©|ë§¨ì…˜)\b',
    
    # ê¸ˆì•¡ (ë¯¼ê°ì •ë³´ì¼ ìˆ˜ ìˆëŠ” ê²½ìš°)
    'money_amount': r'\b\d{1,3}(?:,\d{3})*\s*(?:ì›|ë§Œì›|ì–µì›|ë‹¬ëŸ¬|ì—”)\b',
    
    # ì‚¬ì—…ìë“±ë¡ë²ˆí˜¸
    'business_number': r'\b\d{3}[-\s]?\d{2}[-\s]?\d{5}\b',
    
    # ì™¸êµ­ì¸ë“±ë¡ë²ˆí˜¸
    'foreign_registration': r'\b\d{6}[-\s]?[5-8]\d{6}\b',
}

# ìœ„í—˜ë„ ê°€ì¤‘ì¹˜ (100ì  ë§Œì ) - ì–¼êµ´ ê°€ì¤‘ì¹˜ ë‚®ì¶¤
RISK_WEIGHTS = {
    # ì •ê·œì‹ìœ¼ë¡œ íƒì§€ ê°€ëŠ¥í•œ í•­ëª©
    'phone': 25,
    'email': 15,
    'rrn': 50,  # ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ ìµœê³  ìœ„í—˜
    'address': 20,
    'detailed_address': 30,
    'school': 12,
    'name': 3,  # ì´ë¦„ ë‹¨ë… ê°€ì¤‘ì¹˜ ë‚®ì¶¤ (í˜¸ì¹­ ì—†ëŠ” ê²½ìš°)
    'name_with_title': 8,  # í˜¸ì¹­ ìˆëŠ” ê²½ìš°
    'credit_card': 45,
    'account': 35,
    'birth_date': 25,
    'car_number': 20,
    'passport': 45,
    'driver_license': 40,
    'workplace': 15,
    'ip_address': 18,
    
    # Geminië¡œ íƒì§€í•˜ëŠ” í•­ëª© - ì–¼êµ´ ê°€ì¤‘ì¹˜ ëŒ€í­ ë‚®ì¶¤
    'face_clear': 12,  # 30 -> 12ë¡œ ê°ì†Œ (ì„ ëª…í•œ ì–¼êµ´)
    'face': 8,  # 20 -> 8ë¡œ ê°ì†Œ (ì¼ë°˜ ì–¼êµ´)
    'student_id': 40,  # í•™ìƒì¦
    'pharmacy_bag': 38,  # ì•½ë´‰íˆ¬ (ì§ˆë³‘ì •ë³´)
    'delivery_label': 35,  # ìš´ì†¡ì¥ (ì£¼ì†Œ+ì „í™”ë²ˆí˜¸)
    'wedding_invitation': 25,  # ì²­ì²©ì¥ (ì´ë¦„+ì£¼ì†Œ+ì „í™”ë²ˆí˜¸)
    'id_card': 50,  # ì‹ ë¶„ì¦
    'body_identifiable': 15,  # ì‹ë³„ ê°€ëŠ¥í•œ ì‹ ì²´
    'background_info': 12,  # ë°°ê²½ì˜ ê°œì¸ì •ë³´
    'handwriting': 10,  # í•„ì 
    'fingerprint': 35,  # ì§€ë¬¸
    'medical_info': 40,  # ì˜ë£Œì •ë³´
    'location_landmark': 22,  # ìœ„ì¹˜ íŠ¹ì • ê°€ëŠ¥í•œ ëœë“œë§ˆí¬
}

# ì¡°í•© ìœ„í—˜ íŒ¨í„´
COMBINATION_RISKS = [
    {
        'name': 'ì‹ ì› íŠ¹ì • ìœ„í—˜',
        'pattern': ['name', 'name_with_title', 'school', 'workplace', 'address'],
        'min_count': 2,
        'risk_multiplier': 1.5,
        'description': 'ì´ë¦„ê³¼ ì†Œì† ì •ë³´ë¡œ ê°œì¸ ì‹ ì›ì´ íŠ¹ì •ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤'
    },
    {
        'name': 'ì—°ë½ì²˜ ì¶”ì  ìœ„í—˜',
        'pattern': ['name', 'name_with_title', 'phone', 'address', 'delivery_label'],
        'min_count': 2,
        'risk_multiplier': 2.0,
        'description': 'ì´ë¦„, ì—°ë½ì²˜, ì£¼ì†Œ ì¡°í•©ìœ¼ë¡œ ê°œì¸ ì¶”ì ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤'
    },
    {
        'name': 'ê¸ˆìœµ ì‚¬ê¸° ìœ„í—˜',
        'pattern': ['name', 'name_with_title', 'birth_date', 'phone', 'credit_card', 'account'],
        'min_count': 3,
        'risk_multiplier': 2.5,
        'description': 'ê°œì¸ì •ë³´ì™€ ê¸ˆìœµì •ë³´ ì¡°í•©ìœ¼ë¡œ ê¸ˆìœµ ì‚¬ê¸°ì— ì•…ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤'
    },
    {
        'name': 'ì‹ ë¶„ ë„ìš© ìœ„í—˜',
        'pattern': ['name', 'name_with_title', 'rrn', 'phone', 'birth_date', 'id_card', 'student_id'],
        'min_count': 2,
        'risk_multiplier': 3.0,
        'description': 'ì‹ ë¶„ì¦ê³¼ ê°œì¸ì •ë³´ ì¡°í•©ìœ¼ë¡œ ì‹ ë¶„ ë„ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤'
    },
    {
        'name': 'ì˜ë£Œì •ë³´ ìœ ì¶œ ìœ„í—˜',
        'pattern': ['name', 'name_with_title', 'pharmacy_bag', 'medical_info', 'phone', 'address'],
        'min_count': 2,
        'risk_multiplier': 2.2,
        'description': 'ì§ˆë³‘ì •ë³´ì™€ ê°œì¸ì •ë³´ê°€ ê²°í•©ë˜ì–´ ë¯¼ê°í•œ ì˜ë£Œì •ë³´ê°€ ìœ ì¶œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤'
    },
    {
        'name': 'ìœ„ì¹˜ ì¶”ì  ìœ„í—˜',
        'pattern': ['face_clear', 'address', 'location_landmark', 'car_number'],
        'min_count': 2,
        'risk_multiplier': 1.8,
        'description': 'ì–¼êµ´ê³¼ ìœ„ì¹˜ ì •ë³´ë¡œ ì‹¤ì‹œê°„ ì¶”ì ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤'
    },
    {
        'name': 'ìƒì²´ì •ë³´ ìœ ì¶œ ìœ„í—˜',
        'pattern': ['face_clear', 'fingerprint', 'name', 'name_with_title'],
        'min_count': 2,
        'risk_multiplier': 2.3,
        'description': 'ìƒì²´ì •ë³´ê°€ ë…¸ì¶œë˜ì–´ ìƒì²´ì¸ì¦ ì‹œìŠ¤í…œ ì•…ìš© ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤'
    },
]

# Gemini í”„ë¡¬í”„íŠ¸
GEMINI_ANALYSIS_PROMPT = """
ë‹¹ì‹ ì€ ê°œì¸ì •ë³´ ë³´í˜¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ê°œì¸ì •ë³´ ë…¸ì¶œ ìœ„í—˜ì„ í‰ê°€í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ í•­ëª©ë“¤ì„ ì°¾ì•„ì„œ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:

1. **ì–¼êµ´ (face)**
   - face_clear: ì„ ëª…í•˜ê²Œ ì‹ë³„ ê°€ëŠ¥í•œ ì–¼êµ´ (ê°œìˆ˜)
   - face: íë¦¿í•˜ê±°ë‚˜ ë¶€ë¶„ì ì¸ ì–¼êµ´ (ê°œìˆ˜)

2. **ì‹ ë¶„ì¦/ë¬¸ì„œ (documents)**
   - id_card: ì£¼ë¯¼ë“±ë¡ì¦, ìš´ì „ë©´í—ˆì¦, ì—¬ê¶Œ ë“± ì •ë¶€ ë°œê¸‰ ì‹ ë¶„ì¦
   - student_id: í•™ìƒì¦ (í•™êµëª…, ì´ë¦„, ì‚¬ì§„ í¬í•¨)
   - pharmacy_bag: ì•½ë´‰íˆ¬ (ì•½êµ­ëª…, í™˜ìëª…, ì²˜ë°©ë‚´ì—­)
   - delivery_label: ìš´ì†¡ì¥/íƒë°° ë¼ë²¨ (ì´ë¦„, ì£¼ì†Œ, ì „í™”ë²ˆí˜¸)
   - wedding_invitation: ì²­ì²©ì¥ (ì‹ ë‘ì‹ ë¶€ ì´ë¦„, ì—°ë½ì²˜, ì¥ì†Œ)
   - medical_document: ì˜ë£Œ ê´€ë ¨ ë¬¸ì„œ (ì§„ë‹¨ì„œ, ì²˜ë°©ì „ ë“±)

3. **í…ìŠ¤íŠ¸ ì •ë³´ (text_in_image)**
   - ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œ ê°€ëŠ¥í•œ ëª¨ë“  í…ìŠ¤íŠ¸
   - íŠ¹íˆ ì´ë¦„, ì „í™”ë²ˆí˜¸, ì£¼ì†Œ, ì´ë©”ì¼ ë“±

4. **ìƒì²´ì •ë³´ (biometric)**
   - fingerprint: ì„ ëª…í•œ ì§€ë¬¸
   - handwriting: í•„ì  (ì„œëª… í¬í•¨)

5. **ìœ„ì¹˜/ë°°ê²½ ì •ë³´ (location)**
   - location_landmark: íŠ¹ì • ì¥ì†Œë¥¼ ì‹ë³„í•  ìˆ˜ ìˆëŠ” ëœë“œë§ˆí¬, ê°„íŒ, ê±´ë¬¼ëª…
   - background_info: ë°°ê²½ì— ë…¸ì¶œëœ ê°œì¸ì •ë³´ (í¬ìŠ¤í„°, ëª…í•¨, ì„œë¥˜ ë“±)

6. **ê¸°íƒ€**
   - body_identifiable: ë¬¸ì‹ , í‰í„° ë“± ì‹ë³„ ê°€ëŠ¥í•œ ì‹ ì²´ íŠ¹ì§•
   - car_number: ì°¨ëŸ‰ ë²ˆí˜¸íŒ (í…ìŠ¤íŠ¸ë¡œë„ í™•ì¸)

**ì‘ë‹µ í˜•ì‹ (JSON):**
```json
{
  "detected_items": [
    {
      "type": "face_clear",
      "count": 2,
      "confidence": 0.95,
      "description": "ì„ ëª…í•œ ì–¼êµ´ 2ê°œ ê°ì§€"
    },
    {
      "type": "student_id",
      "count": 1,
      "confidence": 0.88,
      "description": "í•™ìƒì¦ ê°ì§€ - ëŒ€í•™êµëª…, ì´ë¦„, ì‚¬ì§„ í¬í•¨",
      "details": "XXëŒ€í•™êµ í•™ìƒì¦"
    }
  ],
  "extracted_text": "ì´ë¯¸ì§€ì—ì„œ ì¶”ì¶œëœ ëª¨ë“  í…ìŠ¤íŠ¸",
  "risk_assessment": "ì´ë¯¸ì§€ì˜ ì „ë°˜ì ì¸ ê°œì¸ì •ë³´ ë…¸ì¶œ ìœ„í—˜ í‰ê°€",
  "sensitive_areas": ["ì–¼êµ´ ì˜ì—­", "ì‹ ë¶„ì¦ ì˜ì—­"]
}
```

**ì¤‘ìš” ì‚¬í•­:**
- ê° í•­ëª©ì€ ëª…í™•í•˜ê²Œ í™•ì¸ë˜ëŠ” ê²½ìš°ì—ë§Œ í¬í•¨
- confidenceëŠ” 0~1 ì‚¬ì´ì˜ ê°’
- ì˜ì‹¬ìŠ¤ëŸ½ê±°ë‚˜ ë¶ˆí™•ì‹¤í•œ ê²½ìš° confidenceë¥¼ ë‚®ê²Œ ì„¤ì •
- í•œêµ­ì–´ë¡œ ëœ ë¬¸ì„œë‚˜ í…ìŠ¤íŠ¸ë„ ì •í™•íˆ ì¸ì‹
"""

def analyze_text_with_regex(text: str) -> Dict:
    """ì •ê·œì‹ì„ ì‚¬ìš©í•œ í…ìŠ¤íŠ¸ ë¶„ì„ (ìµœì í™” ë²„ì „)"""
    detected_items = []
    total_risk = 0
    
    logger.info(f"í…ìŠ¤íŠ¸ ì •ê·œì‹ ë¶„ì„ ì‹œì‘: {len(text)} ê¸€ì")
    
    if not hasattr(analyze_text_with_regex, '_compiled_patterns'):
        analyze_text_with_regex._compiled_patterns = {
            name: re.compile(pattern, re.IGNORECASE) 
            for name, pattern in PATTERNS.items()
        }
    
    compiled_patterns = analyze_text_with_regex._compiled_patterns
    
    # í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ
    max_text_length = 50000
    if len(text) > max_text_length:
        text = text[:max_text_length]
        logger.warning(f"í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ: {max_text_length}ìë¡œ ìë¦„")
    
    # âœ… ì „í™”ë²ˆí˜¸ë¥¼ ë¨¼ì € ì°¾ì•„ì„œ ì œì™¸ ëª©ë¡ ë§Œë“¤ê¸°
    phone_matches = []
    for pattern_name in ['phone', 'phone_international']:
        if pattern_name in compiled_patterns:
            for match_obj in compiled_patterns[pattern_name].finditer(text):
                phone_matches.append((match_obj.start(), match_obj.end(), match_obj.group(0)))
    
    def is_phone_number(start, end):
        """í•´ë‹¹ ìœ„ì¹˜ê°€ ì „í™”ë²ˆí˜¸ì¸ì§€ í™•ì¸"""
        for p_start, p_end, _ in phone_matches:
            if start >= p_start and end <= p_end:
                return True
        return False
    
    for pattern_name, compiled_pattern in compiled_patterns.items():
        try:
            matches = []
            for match_obj in compiled_pattern.finditer(text):
                # âœ… ê³„ì¢Œë²ˆí˜¸ íŒ¨í„´ì´ë©´ ì „í™”ë²ˆí˜¸ì¸ì§€ í™•ì¸
                if pattern_name == 'account':
                    if is_phone_number(match_obj.start(), match_obj.end()):
                        logger.info(f"âŒ ê³„ì¢Œë²ˆí˜¸ ì œì™¸ (ì „í™”ë²ˆí˜¸ì„): {match_obj.group(0)}")
                        continue
                
                matches.append(match_obj)
            
            if matches:
                count = len(matches)
                risk = RISK_WEIGHTS.get(pattern_name, 10) * min(count, 3)
                total_risk += risk
                
                # ë§ˆìŠ¤í‚¹ ì˜ˆì‹œ
                masked_examples = []
                for match_obj in matches[:2]:
                    match = match_obj.group(0)
                    
                    if pattern_name in ['rrn', 'credit_card', 'account', 'passport', 'driver_license']:
                        if len(match) > 6:
                            masked = match[:2] + '*' * (len(match) - 4) + match[-2:]
                        else:
                            masked = '*' * len(match)
                    else:
                        masked = match[:2] + '*' * max(0, len(match) - 2)
                    
                    masked_examples.append(masked)
                
                detected_items.append({
                    'type': pattern_name,
                    'count': count,
                    'risk_contribution': risk,
                    'examples': masked_examples,
                    'source': 'text'
                })
                
                logger.info(f"íŒ¨í„´ ë°œê²¬: {pattern_name} - {count}ê°œ")
        
        except Exception as e:
            logger.error(f"íŒ¨í„´ {pattern_name} ë§¤ì¹­ ì˜¤ë¥˜: {str(e)}")
    
    return {
        'detected_items': detected_items,
        'total_risk': min(total_risk, 100)
    }

async def analyze_image_with_gemini(image_bytes: bytes) -> Dict:
    """Gemini APIë¥¼ ì‚¬ìš©í•œ ì´ë¯¸ì§€ ë¶„ì„ (ìµœì í™” ë²„ì „)"""
    try:
        logger.info("Gemini API ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘")
        
        # API Key í™•ì¸
        if GEMINI_API_KEY == "YOUR_API_KEY_HERE":
            logger.warning("âš ï¸ Gemini API Keyê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ - ê¸°ë³¸ ë¶„ì„ë§Œ ìˆ˜í–‰")
            return {
                'detected_items': [{
                    'type': 'face',
                    'count': 1,
                    'risk_contribution': 8,
                    'description': 'ì´ë¯¸ì§€ê°€ ì—…ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤ (Gemini API ë¯¸ì„¤ì •)',
                    'source': 'image'
                }],
                'total_risk': 8,
                'detailed_analysis': {'error': 'Gemini API Key not configured'}
            }
        
        # ìµœì í™” 1: ì´ë¯¸ì§€ í¬ê¸° ì œí•œ ë° ì••ì¶•
        from PIL import Image as PILImage
        import io
        
        image = PILImage.open(io.BytesIO(image_bytes))
        
        # ìµœì í™” 2: ì´ë¯¸ì§€ê°€ ë„ˆë¬´ í¬ë©´ ë¦¬ì‚¬ì´ì¦ˆ (API ì „ì†¡ ì†ë„ í–¥ìƒ)
        max_dimension = 2048  # ìµœëŒ€ 2048px
        if max(image.size) > max_dimension:
            ratio = max_dimension / max(image.size)
            new_size = tuple(int(dim * ratio) for dim in image.size)
            image = image.resize(new_size, PILImage.Resampling.LANCZOS)
            logger.info(f"ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ: {image.size}")
        
        # ìµœì í™” 3: Gemini ëª¨ë¸ ì„¤ì • (ë” ë¹ ë¥¸ ì‘ë‹µ)
        generation_config = {
            "temperature": 0.3,  # ë‚®ì€ temperatureë¡œ ë” ë¹ ë¥¸ ì‘ë‹µ
            "top_p": 0.8,
            "top_k": 20,
            "max_output_tokens": 2048,  # ì¶œë ¥ ê¸¸ì´ ì œí•œ
        }
        
        model = genai.GenerativeModel(
            "gemini-2.0-flash-exp",  # ë” ë¹ ë¥¸ ëª¨ë¸ ì‚¬ìš© (ê¸°ì¡´: gemini-2.5-pro)
            generation_config=generation_config
        )
        
        # ìµœì í™” 4: ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ (í•„ìˆ˜ ì •ë³´ë§Œ ìš”ì²­)
        simplified_prompt = """
ì´ë¯¸ì§€ì—ì„œ ê°œì¸ì •ë³´ í•­ëª©ì„ ë¹ ë¥´ê²Œ íƒì§€í•˜ê³  JSONìœ¼ë¡œ ë°˜í™˜í•˜ì„¸ìš”:

í•„ìˆ˜ í•­ëª©ë§Œ ì²´í¬:
- face_clear: ì„ ëª…í•œ ì–¼êµ´ (ê°œìˆ˜)
- face: íë¦¿í•œ ì–¼êµ´ (ê°œìˆ˜)
- id_card: ì‹ ë¶„ì¦ë¥˜
- student_id: í•™ìƒì¦
- pharmacy_bag: ì•½ë´‰íˆ¬
- delivery_label: ìš´ì†¡ì¥
- medical_document: ì˜ë£Œë¬¸ì„œ
- extracted_text: ì´ë¯¸ì§€ ë‚´ í…ìŠ¤íŠ¸ (ì „í™”ë²ˆí˜¸, ì£¼ì†Œ, ì´ë¦„ ë“±)

JSON í˜•ì‹:
{
  "detected_items": [
    {"type": "face_clear", "count": 2, "confidence": 0.9, "description": "ì„¤ëª…"}
  ],
  "extracted_text": "í…ìŠ¤íŠ¸",
  "risk_assessment": "ê°„ë‹¨í•œ í‰ê°€"
}

ì‹ ë¢°ë„ 0.6 ì´ìƒë§Œ í¬í•¨í•˜ì„¸ìš”.
"""
        
        # í”„ë¡¬í”„íŠ¸ì™€ í•¨ê»˜ ë¶„ì„ ìš”ì²­
        response = model.generate_content([simplified_prompt, image])
        
        logger.info(f"Gemini API ì‘ë‹µ ë°›ìŒ: {len(response.text)} ê¸€ì")
        
        # JSON íŒŒì‹±
        response_text = response.text
        
        json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
        if json_match:
            json_str = json_match.group(1)
        else:
            json_match = re.search(r'\{.*\}', response_text, re.DOTALL)
            if json_match:
                json_str = json_match.group(0)
            else:
                logger.warning("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
                return {
                    'detected_items': [{
                        'type': 'face',
                        'count': 1,
                        'risk_contribution': 8,
                        'description': 'ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ (JSON íŒŒì‹± ì‹¤íŒ¨)',
                        'source': 'image'
                    }],
                    'total_risk': 8,
                    'detailed_analysis': {'raw_response': response_text[:500]}
                }
        
        gemini_result = json.loads(json_str)
        logger.info(f"JSON íŒŒì‹± ì„±ê³µ: {len(gemini_result.get('detected_items', []))}ê°œ í•­ëª©")
        
        # ê²°ê³¼ ë³€í™˜
        detected_items = []
        total_risk = 0
        
        for item in gemini_result.get('detected_items', []):
            item_type = item.get('type')
            count = item.get('count', 1)
            confidence = item.get('confidence', 0.8)
            
            # ì‹ ë¢°ë„ 0.6 ì´ìƒë§Œ í¬í•¨ (ë” ì—„ê²©í•˜ê²Œ)
            if confidence >= 0.6 and item_type in RISK_WEIGHTS:
                risk = RISK_WEIGHTS[item_type] * min(count, 3) * confidence
                total_risk += risk
                
                detected_items.append({
                    'type': item_type,
                    'count': count,
                    'risk_contribution': risk,
                    'confidence': confidence,
                    'description': item.get('description', ''),
                    'details': item.get('details', ''),
                    'source': 'image'
                })
                
                logger.info(f"âœ… Gemini íƒì§€: {item_type} - {count}ê°œ (ìœ„í—˜ë„: {risk:.1f}ì )")
        
        # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ë„ ì •ê·œì‹ìœ¼ë¡œ ë¶„ì„ (ìµœì í™”ëœ ë²„ì „ ì‚¬ìš©)
        extracted_text = gemini_result.get('extracted_text', '')
        if extracted_text and len(extracted_text) > 10:  # ì˜ë¯¸ìˆëŠ” í…ìŠ¤íŠ¸ë§Œ
            logger.info(f"ì¶”ì¶œëœ í…ìŠ¤íŠ¸: {len(extracted_text)} ê¸€ì")
            text_analysis = analyze_text_with_regex(extracted_text)
            for item in text_analysis['detected_items']:
                item['source'] = 'image_text'
                detected_items.append(item)
                total_risk += item['risk_contribution']
            logger.info(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì¶”ê°€: {len(text_analysis['detected_items'])}ê°œ í•­ëª©")
        
        logger.info(f"âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ: ì´ ìœ„í—˜ë„ {total_risk:.1f}ì , {len(detected_items)}ê°œ í•­ëª©")
        
        return {
            'detected_items': detected_items,
            'total_risk': min(total_risk, 100),
            'detailed_analysis': {
                'gemini_raw': gemini_result,
                'extracted_text': extracted_text[:200] if extracted_text else '',  # ì¼ë¶€ë§Œ ì €ì¥
                'risk_assessment': gemini_result.get('risk_assessment', '')[:200]
            }
        }
    
    except Exception as e:
        logger.error(f"âŒ Gemini API ë¶„ì„ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return {
            'detected_items': [{
                'type': 'face',
                'count': 1,
                'risk_contribution': 8,
                'description': f'ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)[:100]}',
                'source': 'image'
            }],
            'total_risk': 8,
            'detailed_analysis': {'error': str(e)[:200]}
        }

def analyze_combination_risks(detected_items: List[Dict]) -> List[Dict]:
    """ì¡°í•© ìœ„í—˜ ë¶„ì„"""
    combination_risks = []
    detected_types = set([item['type'] for item in detected_items])
    
    for combo_risk in COMBINATION_RISKS:
        pattern_match_count = sum(1 for pattern_type in combo_risk['pattern'] 
                                if pattern_type in detected_types)
        
        if pattern_match_count >= combo_risk['min_count']:
            matched_types = [t for t in combo_risk['pattern'] if t in detected_types]
            
            combination_risks.append({
                'name': combo_risk['name'],
                'matched_types': matched_types,
                'risk_multiplier': combo_risk['risk_multiplier'],
                'description': combo_risk['description'],
                'severity': 'high' if combo_risk['risk_multiplier'] >= 2.0 else 'medium'
            })
            
            logger.info(f"ì¡°í•© ìœ„í—˜ ë°œê²¬: {combo_risk['name']}")
    
    return combination_risks

def get_risk_level(score: int) -> str:
    """ìœ„í—˜ë„ ë ˆë²¨ íŒì •"""
    if score >= 70:
        return "ë§¤ìš° ìœ„í—˜"
    elif score >= 50:
        return "ìœ„í—˜"
    elif score >= 30:
        return "ì£¼ì˜"
    elif score >= 10:
        return "ì–‘í˜¸"
    else:
        return "ì•ˆì „"

def generate_recommendations(detected_items: List[Dict], combination_risks: List[Dict]) -> List[str]:
    """ê°œì„  ê¶Œê³ ì‚¬í•­ ìƒì„±"""
    recommendations = []
    
    type_messages = {
        'phone': 'ğŸ“± ì „í™”ë²ˆí˜¸: ë’·ìë¦¬ë¥¼ ê°€ë¦¬ê±°ë‚˜ ì‚­ì œí•˜ì„¸ìš”.',
        'email': 'ğŸ“§ ì´ë©”ì¼ ì£¼ì†Œ: ìŠ¤íŒ¸ ìœ„í—˜ì´ ìˆìŠµë‹ˆë‹¤.',
        'rrn': 'âš ï¸ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸: ì ˆëŒ€ ê³µê°œí•˜ì§€ ë§ˆì„¸ìš”! ì¦‰ì‹œ ì‚­ì œí•˜ì„¸ìš”.',
        'address': 'ğŸ“ ì£¼ì†Œ: ë™ ë‹¨ìœ„ê¹Œì§€ë§Œ ê³µê°œí•˜ì„¸ìš”.',
        'detailed_address': 'ğŸ  ìƒì„¸ ì£¼ì†Œ: ë²ˆì§€ìˆ˜/í˜¸ìˆ˜ë¥¼ ì‚­ì œí•˜ì„¸ìš”.',
        'school': 'ğŸ« í•™êµëª…: ì‹ ì› íŒŒì•…ì˜ ë‹¨ì„œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'name': 'ğŸ‘¤ ì‹¤ëª…: ë‹¤ë¥¸ ì •ë³´ì™€ ê²°í•© ì‹œ ì‹ ì› íŠ¹ì • ê°€ëŠ¥.',
        'name_with_title': 'ğŸ‘¤ ì‹¤ëª…(í˜¸ì¹­): ì‹ ì› íŠ¹ì • ê°€ëŠ¥ì„±ì´ ë†’ìŠµë‹ˆë‹¤.',
        'credit_card': 'ğŸ’³ ì¹´ë“œë²ˆí˜¸: ì¦‰ì‹œ ì‚­ì œí•˜ì„¸ìš”!',
        'account': 'ğŸ¦ ê³„ì¢Œë²ˆí˜¸: ê¸ˆìœµ ì •ë³´ëŠ” ì ˆëŒ€ ê³µê°œí•˜ì§€ ë§ˆì„¸ìš”.',
        'face': 'ğŸ˜Š ì–¼êµ´: ë‹¤ë¥¸ ì •ë³´ì™€ ê²°í•© ì‹œ ì£¼ì˜í•˜ì„¸ìš”.',
        'face_clear': 'âš ï¸ ì„ ëª…í•œ ì–¼êµ´: ë‹¤ë¥¸ ê°œì¸ì •ë³´ì™€ í•¨ê»˜ ìˆìœ¼ë©´ ìœ„í—˜í•©ë‹ˆë‹¤.',
        'workplace': 'ğŸ¢ ì§ì¥ ì •ë³´: ì‹ ì› íŒŒì•…ì— í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'birth_date': 'ğŸ“… ìƒë…„ì›”ì¼: ì‹ ì› ë„ìš©ì— ì•…ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'car_number': 'ğŸš— ì°¨ëŸ‰ë²ˆí˜¸: ê°€ë ¤ì£¼ì„¸ìš”.',
        'passport': 'âœˆï¸ ì—¬ê¶Œ: ì¦‰ì‹œ ì‚­ì œí•˜ì„¸ìš”.',
        'driver_license': 'ğŸªª ìš´ì „ë©´í—ˆ: ì‹ ë¶„ì¦ ì •ë³´ëŠ” ì ˆëŒ€ ê³µê°œí•˜ì§€ ë§ˆì„¸ìš”.',
        'id_card': 'âš ï¸ ì‹ ë¶„ì¦: ì ˆëŒ€ ê³µê°œí•˜ì§€ ë§ˆì„¸ìš”!',
        'student_id': 'ğŸ“ í•™ìƒì¦: ì´ë¦„, ì‚¬ì§„, í•™êµ ì •ë³´ê°€ ë…¸ì¶œë©ë‹ˆë‹¤.',
        'pharmacy_bag': 'ğŸ’Š ì•½ë´‰íˆ¬: ì§ˆë³‘ ì •ë³´ê°€ ë…¸ì¶œë©ë‹ˆë‹¤. í™˜ìëª…ê³¼ ì²˜ë°©ë‚´ì—­ì„ ê°€ë¦¬ì„¸ìš”.',
        'delivery_label': 'ğŸ“¦ ìš´ì†¡ì¥: ì´ë¦„, ì£¼ì†Œ, ì „í™”ë²ˆí˜¸ê°€ ëª¨ë‘ ë…¸ì¶œë©ë‹ˆë‹¤.',
        'wedding_invitation': 'ğŸ’’ ì²­ì²©ì¥: ì—°ë½ì²˜ì™€ ì¥ì†Œ ì •ë³´ë¥¼ ê°€ë¦¬ì„¸ìš”.',
        'ip_address': 'ğŸŒ IP ì£¼ì†Œ: ìœ„ì¹˜ ì¶”ì ì— ì•…ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'fingerprint': 'ğŸ‘† ì§€ë¬¸: ìƒì²´ì¸ì¦ ì‹œìŠ¤í…œ ì•…ìš© ê°€ëŠ¥, ê°€ë ¤ì£¼ì„¸ìš”.',
        'handwriting': 'âœï¸ í•„ì : ì„œëª…ì´ë‚˜ í•„ì²´ë¥¼ ê°€ë ¤ì£¼ì„¸ìš”.',
        'medical_info': 'ğŸ¥ ì˜ë£Œì •ë³´: ë¯¼ê°í•œ ê±´ê°•ì •ë³´ê°€ ë…¸ì¶œë©ë‹ˆë‹¤.',
        'location_landmark': 'ğŸ—ºï¸ ìœ„ì¹˜ì •ë³´: ëœë“œë§ˆí¬ë‚˜ ê°„íŒì„ ê°€ë ¤ì£¼ì„¸ìš”.',
    }
    
    detected_types = set([item['type'] for item in detected_items])
    for item_type in detected_types:
        if item_type in type_messages:
            recommendations.append(type_messages[item_type])
    
    # ì¡°í•© ìœ„í—˜ ê¶Œê³ 
    for combo_risk in combination_risks:
        if combo_risk['severity'] == 'high':
            recommendations.append(f"âš ï¸ {combo_risk['description']}")
        else:
            recommendations.append(f"ğŸ’¡ {combo_risk['description']}")
    
    if len(detected_items) > 5:
        recommendations.append('âš ï¸ ë‹¤ìˆ˜ì˜ ê°œì¸ì •ë³´ ë…¸ì¶œ: ì „ë°˜ì ì¸ ì¬ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.')
    
    if not recommendations:
        recommendations.append('âœ… ê°œì¸ì •ë³´ ë…¸ì¶œ ìœ„í—˜ì´ ë‚®ìŠµë‹ˆë‹¤. ê³„ì† ì£¼ì˜í•˜ì„¸ìš”.')
    
    return recommendations

def generate_personalized_feedback(detected_items: List[Dict], 
                                   combination_risks: List[Dict],
                                   user_context: Optional[Dict] = None) -> str:
    """ê°œì¸ ë§ì¶¤í˜• í”¼ë“œë°± ìƒì„±"""
    risk_types = Counter([item['type'] for item in detected_items])
    total_risk = sum([item['risk_contribution'] for item in detected_items])
    
    feedback_parts = []
    
    # ì „ë°˜ì  í‰ê°€
    if total_risk >= 70:
        feedback_parts.append("âš ï¸ ë§¤ìš° ìœ„í—˜í•œ ìˆ˜ì¤€ì˜ ê°œì¸ì •ë³´ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì¡°ì¹˜í•˜ì„¸ìš”.")
    elif total_risk >= 50:
        feedback_parts.append("âš¡ ì£¼ì˜ê°€ í•„ìš”í•œ ìˆ˜ì¤€ì˜ ê°œì¸ì •ë³´ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    elif total_risk >= 30:
        feedback_parts.append("ğŸ’¡ ì¼ë¶€ ê°œì¸ì •ë³´ê°€ ë…¸ì¶œë˜ì–´ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        feedback_parts.append("âœ… ê°œì¸ì •ë³´ ë…¸ì¶œ ìœ„í—˜ì´ ë¹„êµì  ë‚®ìŠµë‹ˆë‹¤.")
    
    # ì£¼ìš” ìœ„í—˜ ê°•ì¡°
    high_risk_items = [
        ('id_card', 'ì‹ ë¶„ì¦'),
        ('rrn', 'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸'),
        ('credit_card', 'ì¹´ë“œë²ˆí˜¸'),
        ('pharmacy_bag', 'ì•½ë´‰íˆ¬'),
        ('student_id', 'í•™ìƒì¦'),
        ('delivery_label', 'ìš´ì†¡ì¥'),
        ('passport', 'ì—¬ê¶Œ'),
        ('driver_license', 'ìš´ì „ë©´í—ˆì¦'),
    ]
    
    critical_items = [name for type_key, name in high_risk_items if type_key in risk_types]
    if critical_items:
        feedback_parts.append(f"ê°€ì¥ ì‹¬ê°í•œ ìœ„í—˜: **{critical_items[0]}** ë…¸ì¶œì…ë‹ˆë‹¤.")
    
    # ì¡°í•© ìœ„í—˜
    if combination_risks:
        high_severity = [r for r in combination_risks if r.get('severity') == 'high']
        if high_severity:
            feedback_parts.append(f"âŒ {high_severity[0]['description']}")
    
    # êµ¬ì²´ì  ì¡°ì–¸
    if 'face_clear' in risk_types and len([item for item in detected_items if item['type'] not in ['face', 'face_clear']]) > 2:
        feedback_parts.append("ì–¼êµ´ê³¼ ë‹¤ë¥¸ ê°œì¸ì •ë³´ê°€ í•¨ê»˜ ë…¸ì¶œë˜ì–´ ìˆì–´ ì‹ ì› íŠ¹ì • ìœ„í—˜ì´ ë†’ìŠµë‹ˆë‹¤.")
    
    if 'id_card' in risk_types or 'student_id' in risk_types:
        feedback_parts.append("ì‹ ë¶„ì¦ë¥˜ëŠ” ë°˜ë“œì‹œ ëª¨ìì´í¬ ì²˜ë¦¬í•˜ì„¸ìš”.")
    
    if any(key in risk_types for key in ['pharmacy_bag', 'medical_info']):
        feedback_parts.append("ì˜ë£Œì •ë³´ëŠ” ë§¤ìš° ë¯¼ê°í•œ ê°œì¸ì •ë³´ì…ë‹ˆë‹¤. ë…¸ì¶œì„ í”¼í•˜ì„¸ìš”.")
    
    return " ".join(feedback_parts)

# API ì—”ë“œí¬ì¸íŠ¸
@app.get("/")
async def root():
    return {
        "message": "Gemini ê¸°ë°˜ ê°œì¸ì •ë³´ ìœ„í—˜ ìê°€ ì§„ë‹¨ ì„œë¹„ìŠ¤ API",
        "version": "4.2 (ì„±ëŠ¥ ìµœì í™”)",
        "features": [
            "Google Gemini AI ì´ë¯¸ì§€ ë¶„ì„ (Flash ëª¨ë¸ - ë” ë¹ ë¦„)",
            "ì •ê·œì‹ ê¸°ë°˜ í…ìŠ¤íŠ¸ ë¶„ì„ (íŒ¨í„´ ì»´íŒŒì¼ ìºì‹±)",
            "ì‹ ë¶„ì¦/í•™ìƒì¦/ì•½ë´‰íˆ¬/ìš´ì†¡ì¥ ê°ì§€",
            "ì–¼êµ´/ìƒì²´ì •ë³´ íƒì§€ (ê°€ì¤‘ì¹˜ ì¡°ì •)",
            "ì¡°í•© ìœ„í—˜ ë¶„ì„",
            "ê°œì¸ ë§ì¶¤ í”¼ë“œë°±"
        ],
        "optimizations": [
            "ì •ê·œì‹ íŒ¨í„´ ì»´íŒŒì¼ ìºì‹±ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë¶„ì„ ì†ë„ í–¥ìƒ",
            "Gemini Flash ëª¨ë¸ ì‚¬ìš©ìœ¼ë¡œ ì´ë¯¸ì§€ ë¶„ì„ ì†ë„ 2-3ë°° í–¥ìƒ",
            "ì´ë¯¸ì§€ ìë™ ë¦¬ì‚¬ì´ì¦ˆ (ìµœëŒ€ 2048px)",
            "í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (5ë§Œì)",
            "ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ë¡œ ì‘ë‹µ ì‹œê°„ ë‹¨ì¶•"
        ],
        "improvements": [
            "ì´ë¦„: í˜¸ì¹­ì´ ìˆëŠ” ê²½ìš°ë§Œ íƒì§€í•˜ì—¬ ì˜¤íƒ ê°ì†Œ",
            "ì–¼êµ´: face_clear 30â†’12, face 20â†’8ë¡œ ê°€ì¤‘ì¹˜ ëŒ€í­ ê°ì†Œ"
        ],
        "supported_items": list(RISK_WEIGHTS.keys())
    }

@app.post("/analyze/text", response_model=AnalysisResponse)
async def analyze_text_endpoint(request: TextAnalysisRequest):
    """í…ìŠ¤íŠ¸ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        if not request.text:
            raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        logger.info(f"í…ìŠ¤íŠ¸ ë¶„ì„ ìš”ì²­: {len(request.text)} ê¸€ì")
        
        analysis = analyze_text_with_regex(request.text)
        combination_risks = analyze_combination_risks(analysis['detected_items'])
        
        combo_bonus = sum(risk['risk_multiplier'] * 10 for risk in combination_risks)
        final_risk = min(analysis['total_risk'] + combo_bonus, 100)
        
        recommendations = generate_recommendations(analysis['detected_items'], combination_risks)
        risk_level = get_risk_level(final_risk)
        personalized_feedback = generate_personalized_feedback(
            analysis['detected_items'], 
            combination_risks, 
            request.user_context
        )
        
        return AnalysisResponse(
            risk_score=int(final_risk),
            detected_items=analysis['detected_items'],
            combination_risks=combination_risks,
            recommendations=recommendations,
            personalized_feedback=personalized_feedback,
            risk_level=risk_level
        )
    
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze/image", response_model=AnalysisResponse)
async def analyze_image_endpoint(file: UploadFile = File(...), user_context: str = None):
    """ì´ë¯¸ì§€ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ (Gemini AI ì‚¬ìš©)"""
    try:
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        
        logger.info(f"ì´ë¯¸ì§€ ë¶„ì„ ìš”ì²­: {file.filename}")
        
        contents = await file.read()
        analysis = await analyze_image_with_gemini(contents)
        combination_risks = analyze_combination_risks(analysis['detected_items'])
        
        combo_bonus = sum(risk['risk_multiplier'] * 10 for risk in combination_risks)
        final_risk = min(analysis['total_risk'] + combo_bonus, 100)
        
        recommendations = generate_recommendations(analysis['detected_items'], combination_risks)
        risk_level = get_risk_level(final_risk)
        
        context_dict = {}
        if user_context:
            try:
                context_dict = json.loads(user_context)
            except:
                context_dict = {'activity_type': user_context}
        
        personalized_feedback = generate_personalized_feedback(
            analysis['detected_items'], 
            combination_risks, 
            context_dict
        )
        
        logger.info(f"ë¶„ì„ ì™„ë£Œ: ìœ„í—˜ë„ {final_risk}, íƒì§€ í•­ëª© {len(analysis['detected_items'])}ê°œ")
        
        return AnalysisResponse(
            risk_score=int(final_risk),
            detected_items=analysis['detected_items'],
            combination_risks=combination_risks,
            recommendations=recommendations,
            personalized_feedback=personalized_feedback,
            risk_level=risk_level,
            detailed_analysis=analysis.get('detailed_analysis')
        )
    
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze/combined")
async def analyze_combined_endpoint(
    text: Optional[str] = None,
    file: Optional[UploadFile] = File(None),
    user_context: Optional[str] = None
):
    """í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ í†µí•© ë¶„ì„ (Gemini + ì •ê·œì‹)"""
    try:
        logger.info("í†µí•© ë¶„ì„ ìš”ì²­")
        
        total_risk = 0
        all_detected_items = []
        detailed_analysis = {}
        
        # í…ìŠ¤íŠ¸ ë¶„ì„ (ì •ê·œì‹)
        if text:
            logger.info(f"í…ìŠ¤íŠ¸ ë¶„ì„: {len(text)} ê¸€ì")
            text_analysis = analyze_text_with_regex(text)
            total_risk += text_analysis['total_risk']
            all_detected_items.extend(text_analysis['detected_items'])
        
        # ì´ë¯¸ì§€ ë¶„ì„ (Gemini AI)
        if file:
            logger.info(f"ì´ë¯¸ì§€ ë¶„ì„: {file.filename}")
            contents = await file.read()
            image_analysis = await analyze_image_with_gemini(contents)
            total_risk += image_analysis['total_risk']
            all_detected_items.extend(image_analysis['detected_items'])
            detailed_analysis = image_analysis.get('detailed_analysis', {})
        
        # ì¡°í•© ìœ„í—˜ ë¶„ì„
        combination_risks = analyze_combination_risks(all_detected_items)
        combo_bonus = sum(risk['risk_multiplier'] * 10 for risk in combination_risks)
        final_risk = min(total_risk + combo_bonus, 100)
        
        recommendations = generate_recommendations(all_detected_items, combination_risks)
        risk_level = get_risk_level(final_risk)
        
        context_dict = {}
        if user_context:
            try:
                context_dict = json.loads(user_context)
            except:
                context_dict = {'activity_type': user_context}
        
        personalized_feedback = generate_personalized_feedback(
            all_detected_items, 
            combination_risks, 
            context_dict
        )
        
        logger.info(f"í†µí•© ë¶„ì„ ì™„ë£Œ: ìœ„í—˜ë„ {final_risk}, í•­ëª© {len(all_detected_items)}ê°œ")
        
        return AnalysisResponse(
            risk_score=int(final_risk),
            detected_items=all_detected_items,
            combination_risks=combination_risks,
            recommendations=recommendations,
            personalized_feedback=personalized_feedback,
            risk_level=risk_level,
            detailed_analysis=detailed_analysis
        )
    
    except Exception as e:
        logger.error(f"í†µí•© ë¶„ì„ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    gemini_status = "active" if GEMINI_API_KEY != "YOUR_API_KEY_HERE" else "not_configured"
    
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "gemini_ai": gemini_status,
            "text_analysis": "active",
            "combination_analysis": "active"
        },
        "supported_patterns": len(PATTERNS),
        "supported_risk_items": len(RISK_WEIGHTS)
    }

@app.get("/api/info")
async def api_info():
    """API ìƒì„¸ ì •ë³´"""
    return {
        "version": "4.2",
        "description": "Gemini AI ê¸°ë°˜ ê°œì¸ì •ë³´ ìœ„í—˜ ìê°€ ì§„ë‹¨ ì„œë¹„ìŠ¤ (ì„±ëŠ¥ ìµœì í™”)",
        "text_patterns": list(PATTERNS.keys()),
        "image_detection": list(set(RISK_WEIGHTS.keys()) - set(PATTERNS.keys())),
        "combination_risks": [r['name'] for r in COMBINATION_RISKS],
        "risk_weights": RISK_WEIGHTS,
        "improvements": {
            "name_detection": "í˜¸ì¹­ì´ ìˆëŠ” ê²½ìš°(ë‹˜, ì”¨, ì„ ìƒë‹˜ ë“±)ë§Œ íƒì§€í•˜ì—¬ ì˜¤íƒ ê°ì†Œ",
            "face_weights": {
                "face_clear": "30 â†’ 12 (60% ê°ì†Œ)",
                "face": "20 â†’ 8 (60% ê°ì†Œ)"
            }
        },
        "performance_optimizations": {
            "text_analysis": [
                "ì •ê·œì‹ íŒ¨í„´ ì»´íŒŒì¼ ìºì‹± (ì²« í˜¸ì¶œ í›„ ì¬ì‚¬ìš©)",
                "findall ëŒ€ì‹  finditer ì‚¬ìš© (ë©”ëª¨ë¦¬ íš¨ìœ¨)",
                "í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ìµœëŒ€ 5ë§Œì)",
                "ë§ˆìŠ¤í‚¹ ì˜ˆì‹œ ìµœëŒ€ 2ê°œë¡œ ì œí•œ"
            ],
            "image_analysis": [
                "Gemini Flash ëª¨ë¸ ì‚¬ìš© (Pro ëŒ€ë¹„ 2-3ë°° ë¹ ë¦„)",
                "ì´ë¯¸ì§€ ìë™ ë¦¬ì‚¬ì´ì¦ˆ (ìµœëŒ€ 2048px)",
                "ê°„ì†Œí™”ëœ í”„ë¡¬í”„íŠ¸ (í•„ìˆ˜ í•­ëª©ë§Œ ìš”ì²­)",
                "max_output_tokens ì œí•œ (2048)",
                "temperature 0.3 (ë” ë¹ ë¥¸ ì‘ë‹µ)",
                "ì‹ ë¢°ë„ ì„ê³„ê°’ 0.6 (ì •í™•ë„ ìš°ì„ )"
            ],
            "expected_speedup": {
                "text_only": "10-30% ë¹ ë¦„ (íŒ¨í„´ ìºì‹±)",
                "image_only": "50-70% ë¹ ë¦„ (Flash ëª¨ë¸ + ë¦¬ì‚¬ì´ì¦ˆ)",
                "combined": "40-60% ë¹ ë¦„"
            }
        },
        "endpoints": {
            "POST /analyze/text": "í…ìŠ¤íŠ¸ ë¶„ì„ (ì •ê·œì‹)",
            "POST /analyze/image": "ì´ë¯¸ì§€ ë¶„ì„ (Gemini AI)",
            "POST /analyze/combined": "í…ìŠ¤íŠ¸ + ì´ë¯¸ì§€ í†µí•© ë¶„ì„",
            "POST /test/analyze": "í…ŒìŠ¤íŠ¸ìš© ë¶„ì„ (ìƒì„¸ ë¡œê·¸)",
            "GET /health": "ì„œë²„ ìƒíƒœ í™•ì¸",
            "GET /api/info": "API ì •ë³´"
        }
    }

@app.post("/test/analyze")
async def test_analyze(
    text: Optional[str] = None,
    file: Optional[UploadFile] = File(None)
):
    """í…ŒìŠ¤íŠ¸ìš© ìƒì„¸ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸ (ë””ë²„ê¹…ìš©)"""
    try:
        logger.info("=" * 50)
        logger.info("ğŸ” í…ŒìŠ¤íŠ¸ ë¶„ì„ ì‹œì‘")
        logger.info("=" * 50)
        
        result = {
            "text_analysis": None,
            "image_analysis": None,
            "final_result": None
        }
        
        # í…ìŠ¤íŠ¸ ë¶„ì„
        if text:
            logger.info(f"ğŸ“ í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)} ê¸€ì")
            logger.info(f"ğŸ“ í…ìŠ¤íŠ¸ ë‚´ìš©: {text[:100]}...")
            text_result = analyze_text_with_regex(text)
            result["text_analysis"] = text_result
            logger.info(f"âœ… í…ìŠ¤íŠ¸ ë¶„ì„ ì™„ë£Œ: {len(text_result['detected_items'])}ê°œ í•­ëª©, ìœ„í—˜ë„ {text_result['total_risk']}")
        
        # ì´ë¯¸ì§€ ë¶„ì„
        if file:
            logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ íŒŒì¼: {file.filename}")
            contents = await file.read()
            logger.info(f"ğŸ–¼ï¸ ì´ë¯¸ì§€ í¬ê¸°: {len(contents)} bytes")
            image_result = await analyze_image_with_gemini(contents)
            result["image_analysis"] = image_result
            logger.info(f"âœ… ì´ë¯¸ì§€ ë¶„ì„ ì™„ë£Œ: {len(image_result['detected_items'])}ê°œ í•­ëª©, ìœ„í—˜ë„ {image_result['total_risk']}")
        
        # í†µí•© ê²°ê³¼
        all_items = []
        total_risk = 0
        
        if result["text_analysis"]:
            all_items.extend(result["text_analysis"]["detected_items"])
            total_risk += result["text_analysis"]["total_risk"]
        
        if result["image_analysis"]:
            all_items.extend(result["image_analysis"]["detected_items"])
            total_risk += result["image_analysis"]["total_risk"]
        
        combination_risks = analyze_combination_risks(all_items)
        combo_bonus = sum(risk['risk_multiplier'] * 10 for risk in combination_risks)
        final_risk = min(total_risk + combo_bonus, 100)
        
        result["final_result"] = {
            "total_items": len(all_items),
            "base_risk": total_risk,
            "combo_bonus": combo_bonus,
            "final_risk": final_risk,
            "risk_level": get_risk_level(final_risk),
            "combination_risks_count": len(combination_risks)
        }
        
        logger.info("=" * 50)
        logger.info(f"ğŸ¯ ìµœì¢… ê²°ê³¼: {final_risk}ì  ({result['final_result']['risk_level']})")
        logger.info(f"   - ê¸°ë³¸ ìœ„í—˜: {total_risk}ì ")
        logger.info(f"   - ì¡°í•© ë³´ë„ˆìŠ¤: {combo_bonus}ì ")
        logger.info(f"   - íƒì§€ í•­ëª©: {len(all_items)}ê°œ")
        logger.info("=" * 50)
        
        return result
    
    except Exception as e:
        logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}", exc_info=True)
        return {"error": str(e)}

if __name__ == "__main__":
    logger.info("ğŸš€ Gemini ê¸°ë°˜ ê°œì¸ì •ë³´ ë¶„ì„ ì„œë²„ ì‹œì‘...")
    logger.info(f"ğŸ“Š ì§€ì› íŒ¨í„´: {len(PATTERNS)}ê°œ")
    logger.info(f"ğŸ” ìœ„í—˜ í•­ëª©: {len(RISK_WEIGHTS)}ê°œ")
    logger.info(f"âš ï¸ ì¡°í•© ìœ„í—˜: {len(COMBINATION_RISKS)}ê°œ")
    logger.info("")
    logger.info("âœ¨ v4.2 ê°œì„ ì‚¬í•­:")
    logger.info("   [ì •í™•ë„] ì´ë¦„: í˜¸ì¹­(ë‹˜/ì”¨/ì„ ìƒë‹˜ ë“±) ìˆëŠ” ê²½ìš°ë§Œ íƒì§€")
    logger.info("   [ì •í™•ë„] ì–¼êµ´: face_clear 30â†’12, face 20â†’8ë¡œ ê°€ì¤‘ì¹˜ ê°ì†Œ")
    logger.info("   [ì„±ëŠ¥] ì •ê·œì‹ íŒ¨í„´ ì»´íŒŒì¼ ìºì‹±ìœ¼ë¡œ í…ìŠ¤íŠ¸ ë¶„ì„ 10-30% ë¹ ë¦„")
    logger.info("   [ì„±ëŠ¥] Gemini Flash ëª¨ë¸ë¡œ ì´ë¯¸ì§€ ë¶„ì„ 50-70% ë¹ ë¦„")
    logger.info("   [ì„±ëŠ¥] ì´ë¯¸ì§€ ìë™ ë¦¬ì‚¬ì´ì¦ˆ (ìµœëŒ€ 2048px)")
    logger.info("   [ì„±ëŠ¥] í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ (ìµœëŒ€ 5ë§Œì)")
    logger.info("")
    
    if GEMINI_API_KEY == "YOUR_API_KEY_HERE":
        logger.warning("âš ï¸ Gemini API Keyê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
        logger.warning("í™˜ê²½ë³€ìˆ˜ GEMINI_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.")
    else:
        logger.info("âœ… Gemini API ì„¤ì • ì™„ë£Œ (Flash ëª¨ë¸ ì‚¬ìš©)")
    
    uvicorn.run(app, host="0.0.0.0", port=8000)