from fastapi import FastAPI, UploadFile, File, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import JSONResponse
from pydantic import BaseModel
import uvicorn
import re
import cv2
import numpy as np
import mediapipe as mp
import easyocr
from typing import List, Dict, Optional
import logging
from datetime import datetime
from collections import Counter
from PIL import Image
from PIL.ExifTags import TAGS, GPSTAGS
import io

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(title="ê°œì¸ì •ë³´ ìœ„í—˜ ìê°€ ì§„ë‹¨ ì„œë¹„ìŠ¤ (ê°œì„ ë¨)")

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# MediaPipe ì´ˆê¸°í™”
mp_face_detection = mp.solutions.face_detection
mp_face_mesh = mp.solutions.face_mesh
mp_pose = mp.solutions.pose
mp_hands = mp.solutions.hands

face_detection = mp_face_detection.FaceDetection(min_detection_confidence=0.5)
face_mesh = mp_face_mesh.FaceMesh(min_detection_confidence=0.5)
pose_detection = mp_pose.Pose(min_detection_confidence=0.5)
hands_detection = mp_hands.Hands(min_detection_confidence=0.5)

# EasyOCR ì´ˆê¸°í™” (í•œêµ­ì–´, ì˜ì–´)
reader = easyocr.Reader(['ko', 'en'], gpu=False)

# Tesseract OCRë„ í•¨ê»˜ ì‚¬ìš© (ë” ì •í™•í•œ ì¸ì‹ì„ ìœ„í•´)
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except ImportError:
    TESSERACT_AVAILABLE = False
    logger.warning("pytesseractë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. EasyOCRë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.")

# ìš”ì²­ ëª¨ë¸
class TextAnalysisRequest(BaseModel):
    text: str
    user_context: Optional[Dict] = None

class AnalysisResponse(BaseModel):
    risk_score: int
    detected_items: List[Dict]
    combination_risks: List[Dict]
    recommendations: List[str]
    personalized_feedback: str
    risk_level: str
    detailed_analysis: Optional[Dict] = None

# ê°œì¸ì •ë³´ íŒ¨í„´ ì •ì˜ (í™•ì¥ë¨)
PATTERNS = {
    'phone': r'(\d{2,3}[-.\s]?\d{3,4}[-.\s]?\d{4})',
    'email': r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}',
    'rrn': r'\d{6}[-\s]?[1-4]\d{6}',
    'address': r'(ì„œìš¸|ë¶€ì‚°|ëŒ€êµ¬|ì¸ì²œ|ê´‘ì£¼|ëŒ€ì „|ìš¸ì‚°|ì„¸ì¢…|ê²½ê¸°|ê°•ì›|ì¶©ë¶|ì¶©ë‚¨|ì „ë¶|ì „ë‚¨|ê²½ë¶|ê²½ë‚¨|ì œì£¼)[\s]?[\w\s]+[ì‹œêµ°êµ¬][\s]?[\w\s]+[ë™ìë©´ë¦¬]',
    'detailed_address': r'\d+[-]?\d*\s*(?:ë²ˆì§€|í˜¸)',
    'school': r'[\w]+(?:ì´ˆë“±í•™êµ|ì¤‘í•™êµ|ê³ ë“±í•™êµ|ëŒ€í•™êµ|ëŒ€í•™|í•™êµ)',
    'name': r'[ê°€-í£]{2,4}(?:ë‹˜|ì”¨|í•™ìƒ|ì„ ìƒ|êµìˆ˜|êµ°|ì–‘)',
    'card': r'\d{4}[-\s]?\d{4}[-\s]?\d{4}[-\s]?\d{4}',
    'account': r'\d{3,6}[-\s]?\d{2,6}[-\s]?\d{6,}',
    'workplace': r'[\w]+(?:íšŒì‚¬|ê¸°ì—…|ë³‘ì›|ì€í–‰|ëŒ€í•™|ê³µì‚¬|ê·¸ë£¹|ì—°êµ¬ì†Œ|ì¬ë‹¨)',
    'birth_date': r'(\d{4})[ë…„\.\-/](\d{1,2})[ì›”\.\-/](\d{1,2})[ì¼]?',
    'age': r'(\d{1,2})[ì„¸ì‚´]|ë‚˜ì´\s*(\d{1,2})',
    'car_number': r'\d{2,3}[ê°€-í£]\d{4}',
    'passport': r'[A-Z]\d{8}',
    # ìš´ì „ë©´í—ˆ íŒ¨í„´ ê°•í™” (ì§€ì—­ ì½”ë“œ 2ìë¦¬ + 2ìë¦¬ + 6ìë¦¬ + 2ìë¦¬)
    'driver_license': r'(?:\d{2}[-\s]?[0-9]{2}|[ê°€-í£]{2}[-\s]?[0-9]{2})[-\s]?\d{6}[-\s]?\d{2}', 
    'sns_id': r'@[a-zA-Z0-9_]{3,}',
    'ip_address': r'\b(?:\d{1,3}\.){3}\d{1,3}\b',
    'medical_info': r'(?:ì§„ë‹¨ì„œ|ì²˜ë°©ì „|ë³‘ëª…|ì§ˆí™˜|ì¹˜ë£Œ|í™˜ì|ë³µìš©|íˆ¬ì•½)',
    'financial_info': r'(?:ì—°ë´‰|ì›”ê¸‰|ê¸‰ì—¬|ì†Œë“|ìì‚°|ëŒ€ì¶œ)',
    'id_card_keywords': r'(?:ì£¼ë¯¼ë“±ë¡ì¦|ìš´ì „ë©´í—ˆì¦|ì—¬ê¶Œ|ì‹ ë¶„ì¦|ë“±ë¡ì¦|ì£¼ë¯¼ë²ˆí˜¸|ë©´í—ˆë²ˆí˜¸)',
    'pharmacy_keywords': r'(?:ì•½êµ­|ì¡°ì œ|ì²˜ë°©|ë³µìš©|íˆ¬ì•½|ìš©ë²•|ìš©ëŸ‰|mg|ì •)',
    # ì—¬ê¶Œ MRZ íŒ¨í„´ (ê³ ê¸‰ íŒ¨í„´)
    'passport_mrz': r'[A-Z0-9<]{30,}'
}

# ìœ„í—˜ë„ ê°€ì¤‘ì¹˜ (í™•ì¥ë¨)
RISK_WEIGHTS = {
    'phone': 25, 'email': 15, 'rrn': 45, 'address': 20, 'detailed_address': 30,
    'school': 12, 'name': 10, 'card': 40, 'account': 35, 'face': 18,
    'face_clear': 25, 'body': 10, 'hands': 8, 'text_in_image': 5,
    'workplace': 15, 'birth_date': 25, 'age': 10, 'car_number': 20,
    'passport': 40, 'driver_license': 35, 'sns_id': 12, 'ip_address': 15,
    'medical_info': 30, 'financial_info': 25, 'metadata': 10,
    'location_exif': 25, 'background_info': 15, 'id_card': 45,
    'pharmacy_bag': 35, 'passport_mrz': 30
}

# ì¡°í•© ìœ„í—˜ íŒ¨í„´
COMBINATION_RISKS = [
    {
        'name': 'ì‹ ì› íŠ¹ì • ìœ„í—˜',
        'pattern': ['name', 'school', 'workplace'],
        'min_count': 2,
        'risk_multiplier': 1.5,
        'description': 'ì´ë¦„ê³¼ í•™êµ/ì§ì¥ ì •ë³´ë¡œ ê°œì¸ ì‹ ì›ì´ íŠ¹ì •ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤'
    },
    {
        'name': 'ì—°ë½ì²˜ ì¶”ì  ìœ„í—˜',
        'pattern': ['name', 'phone', 'address'],
        'min_count': 2,
        'risk_multiplier': 2.0,
        'description': 'ì´ë¦„, ì—°ë½ì²˜, ì£¼ì†Œ ì¡°í•©ìœ¼ë¡œ ê°œì¸ ì¶”ì ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤'
    },
    {
        'name': 'ê¸ˆìœµ ì‚¬ê¸° ìœ„í—˜',
        'pattern': ['name', 'birth_date', 'phone', 'card', 'account'],
        'min_count': 3,
        'risk_multiplier': 2.5,
        'description': 'ê°œì¸ì •ë³´ì™€ ê¸ˆìœµì •ë³´ ì¡°í•©ìœ¼ë¡œ ê¸ˆìœµ ì‚¬ê¸°ì— ì•…ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤'
    },
    {
        'name': 'ê°œì¸ì •ë³´ ë„ìš© ìœ„í—˜',
        'pattern': ['name', 'rrn', 'phone', 'birth_date'],
        'min_count': 2,
        'risk_multiplier': 3.0,
        'description': 'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ì™€ ê°œì¸ì •ë³´ ì¡°í•©ìœ¼ë¡œ ì‹ ë¶„ ë„ìš©ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤'
    },
    {
        'name': 'ìŠ¤í† í‚¹/ê´´ë¡­í˜ ìœ„í—˜',
        'pattern': ['name', 'address', 'school', 'workplace', 'face'],
        'min_count': 2,
        'risk_multiplier': 1.8,
        'description': 'ê°œì¸ í™œë™ ì¥ì†Œ ì¡°í•©ìœ¼ë¡œ ìŠ¤í† í‚¹ì´ë‚˜ ê´´ë¡­í˜ì— ë…¸ì¶œë  ìˆ˜ ìˆìŠµë‹ˆë‹¤'
    },
    {
        'name': 'ìœ„ì¹˜ ì¶”ì  ìœ„í—˜',
        'pattern': ['location_exif', 'address', 'face', 'background_info'],
        'min_count': 2,
        'risk_multiplier': 2.2,
        'description': 'ìœ„ì¹˜ ì •ë³´ì™€ ê°œì¸ ì‹ë³„ ì •ë³´ë¡œ ì‹¤ì‹œê°„ ì¶”ì ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤'
    },
]

def preprocess_for_ocr(image: np.ndarray) -> List[np.ndarray]:
    """OCR ì •í™•ë„ í–¥ìƒì„ ìœ„í•œ ë‹¤ì–‘í•œ ì „ì²˜ë¦¬"""
    processed_images = []
    
    # 1. ì›ë³¸
    processed_images.append(image)
    
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    
    # 2. ê·¸ë ˆì´ìŠ¤ì¼€ì¼ + ì´ì§„í™” (OTSU)
    _, binary = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    processed_images.append(cv2.cvtColor(binary, cv2.COLOR_GRAY2BGR))
    
    # 3. ì ì‘í˜• ì´ì§„í™” (ì‹ ë¶„ì¦ì˜ ê·¸ë¦¼ì ì œê±°ì— ìœ ë¦¬)
    adaptive = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, 
                                     cv2.THRESH_BINARY, 15, 5) # ë¸”ë¡ í¬ê¸° ë° Cê°’ ì¡°ì •
    processed_images.append(cv2.cvtColor(adaptive, cv2.COLOR_GRAY2BGR))
    
    # 4. ë…¸ì´ì¦ˆ ì œê±° + ì´ì§„í™”
    denoised = cv2.fastNlMeansDenoising(gray, None, 10, 7, 21)
    _, binary_denoised = cv2.threshold(denoised, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    processed_images.append(cv2.cvtColor(binary_denoised, cv2.COLOR_GRAY2BGR))
    
    # 5. ëŒ€ë¹„ í–¥ìƒ (CLAHE)
    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8,8))
    enhanced = clahe.apply(gray)
    processed_images.append(cv2.cvtColor(enhanced, cv2.COLOR_GRAY2BGR))
    
    return processed_images

def extract_text_enhanced(image_bytes: bytes) -> Dict[str, str]:
    """í–¥ìƒëœ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ë‹¤ì¤‘ ì „ì²˜ë¦¬ + ë‹¤ì¤‘ OCR ì—”ì§„)"""
    try:
        # ì´ë¯¸ì§€ ë””ì½”ë”©
        nparr = np.frombuffer(image_bytes, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        
        easyocr_texts = []
        tesseract_texts = []
        
        # ë‹¤ì–‘í•œ ì „ì²˜ë¦¬ ì ìš©
        processed_images = preprocess_for_ocr(image)
        
        # ê° ì „ì²˜ë¦¬ëœ ì´ë¯¸ì§€ì—ì„œ OCR ìˆ˜í–‰
        for proc_img in processed_images:
            # EasyOCR
            _, encoded_img = cv2.imencode('.jpg', proc_img)
            ocr_results = reader.readtext(encoded_img.tobytes())
            texts = [text[1] for text in ocr_results]
            easyocr_texts.extend(texts)
            
            # Tesseract OCR (ì‚¬ìš© ê°€ëŠ¥í•œ ê²½ìš°)
            if TESSERACT_AVAILABLE:
                try:
                    # í•œê¸€ + ì˜ì–´ ì¸ì‹
                    custom_config = r'--oem 3 --psm 6 -l kor+eng'
                    tess_text = pytesseract.image_to_string(proc_img, config=custom_config)
                    if tess_text.strip():
                        tesseract_texts.append(tess_text)
                except Exception as e:
                    logger.debug(f"Tesseract OCR ì˜¤ë¥˜: {str(e)}")
        
        # ì¤‘ë³µ ì œê±° ë° ê²°í•©
        unique_easyocr_texts = list(set(easyocr_texts))
        unique_tesseract_texts = list(set(tesseract_texts))
        
        combined_text = ' '.join(unique_easyocr_texts + unique_tesseract_texts)
        
        return {
            'combined_text': combined_text,
            'easyocr_text': ' '.join(unique_easyocr_texts),
            'tesseract_text': ' '.join(unique_tesseract_texts)
        }
    
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ì¶”ì¶œ ì˜¤ë¥˜: {str(e)}")
        return {'combined_text': '', 'easyocr_text': '', 'tesseract_text': ''}


def detect_id_card(image: np.ndarray, all_ocr_texts: Dict[str, str], face_results) -> Dict:
    """ì‹ ë¶„ì¦ ê°ì§€ (ì£¼ë¯¼ë“±ë¡ì¦, ìš´ì „ë©´í—ˆì¦, ì—¬ê¶Œ ë“±) - ì ìˆ˜ ê¸°ë°˜ ë¡œì§ ê°•í™”"""
    id_card_info = {
        'detected': False,
        'type': None,
        'confidence': 0,
        'risk': 0,
        'features_found': [],
        'detection_score': 0
    }
    
    extracted_text = all_ocr_texts['combined_text']
    h, w = image.shape[:2]
    
    # --- 1. íŒ¨í„´ ë° í‚¤ì›Œë“œ ë§¤ì¹­ (ê°€ì¥ ë†’ì€ ì ìˆ˜) ---
    
    # 1.1. ë¯¼ê° ì •ë³´ íŒ¨í„´ ë§¤ì¹­ (ê°€ì¤‘ì¹˜ ë†’ìŒ)
    if re.search(PATTERNS['rrn'], extracted_text):
        id_card_info['features_found'].append('ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ íŒ¨í„´')
        id_card_info['detection_score'] += 35
        id_card_info['type'] = id_card_info['type'] or 'ì£¼ë¯¼ë“±ë¡ì¦' # ì´ˆê¸° íƒ€ì… ì§€ì •
    
    if re.search(PATTERNS['driver_license'], extracted_text):
        id_card_info['features_found'].append('ìš´ì „ë©´í—ˆë²ˆí˜¸ íŒ¨í„´')
        id_card_info['detection_score'] += 30
        id_card_info['type'] = id_card_info['type'] or 'ìš´ì „ë©´í—ˆì¦'
        
    if re.search(PATTERNS['passport_mrz'], extracted_text):
        id_card_info['features_found'].append('ì—¬ê¶Œ MRZ íŒ¨í„´')
        id_card_info['detection_score'] += 25
        id_card_info['type'] = id_card_info['type'] or 'ì—¬ê¶Œ'

    # 1.2. êµì°¨ ê²€ì¦ (EasyOCR/Tesseract ëª¨ë‘ì—ì„œ íŒ¨í„´ ë°œê²¬ ì‹œ ë³´ë„ˆìŠ¤)
    if TESSERACT_AVAILABLE:
        rrn_easy = re.search(PATTERNS['rrn'], all_ocr_texts['easyocr_text'])
        rrn_tess = re.search(PATTERNS['rrn'], all_ocr_texts['tesseract_text'])
        if rrn_easy and rrn_tess:
             id_card_info['features_found'].append('RRN êµì°¨ ê²€ì¦')
             id_card_info['detection_score'] += 10 # ì‹ ë¢°ë„ ë³´ë„ˆìŠ¤

    # 1.3. ì‹ ë¶„ì¦ í‚¤ì›Œë“œ ë§¤ì¹­
    id_keywords = {
        'ì£¼ë¯¼ë“±ë¡ì¦': ['ì£¼ë¯¼ë“±ë¡ì¦', 'ì£¼ë¯¼', 'ë°œê¸‰'],
        'ìš´ì „ë©´í—ˆì¦': ['ìš´ì „ë©´í—ˆì¦', 'ë©´í—ˆ', 'ìš´ì „', 'ë„ë¡œêµí†µ'],
        'ì—¬ê¶Œ': ['PASSPORT', 'REPUBLIC OF KOREA', 'ì—¬ê¶Œ'],
    }
    
    for card_type, keywords in id_keywords.items():
        matches = sum(1 for keyword in keywords if keyword in extracted_text)
        if matches > 0:
            id_card_info['features_found'].append(f'{card_type} í‚¤ì›Œë“œ')
            id_card_info['detection_score'] += (matches * 5)
            id_card_info['type'] = id_card_info['type'] or card_type # ì´ˆê¸° íƒ€ì… ì§€ì •

    # --- 2. í˜•íƒœ ë¶„ì„ ---

    # 2.1. ì¹´ë“œ í˜•íƒœ ë¹„ìœ¨ (ëŒ€ëµ 1.4:1 ~ 1.8:1)
    aspect_ratio = w / h
    if 1.4 <= aspect_ratio <= 1.8:
        id_card_info['features_found'].append('ì¹´ë“œ í˜•íƒœ ë¹„ìœ¨')
        id_card_info['detection_score'] += 10
    
    # --- 3. ì–¼êµ´ êµ¬ì„± ë¶„ì„ (ì¦ëª…ì‚¬ì§„ íŠ¹ì§•) ---
    
    if face_results.detections:
        # 2.2. ë‹¨ì¼ ì–¼êµ´ ê°ì§€ (ì¦ëª…ì‚¬ì§„ì€ ë³´í†µ í•˜ë‚˜)
        if len(face_results.detections) == 1:
            id_card_info['features_found'].append('ë‹¨ì¼ ì¦ëª…ì‚¬ì§„')
            id_card_info['detection_score'] += 10
            
            # 2.3. ì–¼êµ´ì´ ì´ë¯¸ì§€ì˜ ì‘ì€ ë¹„ìœ¨ì„ ì°¨ì§€í•˜ëŠ”ì§€ (ì…€ì¹´ê°€ ì•„ë‹Œ ì¦ëª…ì‚¬ì§„)
            detection = face_results.detections[0]
            bbox = detection.location_data.relative_bounding_box
            face_ratio = bbox.width * bbox.height
            if 0.01 <= face_ratio <= 0.08: # ì´ë¯¸ì§€ì˜ 1%~8% ì •ë„
                id_card_info['features_found'].append('ì‘ì€ ì–¼êµ´ í¬ê¸°')
                id_card_info['detection_score'] += 10

    # --- ìµœì¢… íŒì • ---
    
    # 70ì  ì´ìƒì¼ ë•Œë§Œ ì‹ ë¶„ì¦ìœ¼ë¡œ í™•ì •
    if id_card_info['detection_score'] >= 60:
        id_card_info['detected'] = True
        id_card_info['risk'] = RISK_WEIGHTS['id_card']
        # ì‹ ë¢°ë„ëŠ” ì ìˆ˜ë¥¼ 100ì ìœ¼ë¡œ ì •ê·œí™”
        id_card_info['confidence'] = min(id_card_info['detection_score'] / 100.0, 1.0)
    
    return id_card_info

# (ì´í•˜ ë‚˜ë¨¸ì§€ í•¨ìˆ˜ëŠ” ë³€ê²½ ì—†ìŒ)

def detect_face_quality(image: np.ndarray, face_locations: list) -> Dict:
    """ì–¼êµ´ ì„ ëª…ë„ ë° í¬ê¸° ë¶„ì„"""
    # ... (ê¸°ì¡´ ì½”ë“œ ìœ ì§€) ...
    quality_info = {
        'clear_faces': 0,
        'large_faces': 0,
        'total_faces': len(face_locations)
    }
    
    if not face_locations:
        return quality_info
    
    h, w = image.shape[:2]
    
    for detection in face_locations:
        bbox = detection.location_data.relative_bounding_box
        x = int(bbox.xmin * w)
        y = int(bbox.ymin * h)
        width = int(bbox.width * w)
        height = int(bbox.height * h)
        
        # ì–¼êµ´ ì˜ì—­ ì¶”ì¶œ
        face_roi = image[max(0, y):min(h, y+height), max(0, x):min(w, x+width)]
        
        if face_roi.size > 0:
            # ì„ ëª…ë„ ì¸¡ì • (ë¼í”Œë¼ì‹œì•ˆ ë¶„ì‚°)
            gray = cv2.cvtColor(face_roi, cv2.COLOR_BGR2GRAY)
            laplacian_var = cv2.Laplacian(gray, cv2.CV_64F).var()
            
            if laplacian_var > 100:  # ì„ ëª…í•œ ì–¼êµ´
                quality_info['clear_faces'] += 1
            
            # ì–¼êµ´ í¬ê¸° ë¹„ìœ¨ (ì´ë¯¸ì§€ ëŒ€ë¹„)
            face_ratio = (width * height) / (w * h)
            if face_ratio > 0.05:  # ì´ë¯¸ì§€ì˜ 5% ì´ìƒ
                quality_info['large_faces'] += 1
    
    return quality_info

def extract_exif_data(image_bytes: bytes) -> Dict:
    """EXIF ë©”íƒ€ë°ì´í„° ì¶”ì¶œ"""
    metadata = {
        'has_gps': False,
        'has_datetime': False,
        'camera_info': False,
        'location_risk': 0
    }
    
    try:
        img = Image.open(io.BytesIO(image_bytes))
        exif_data = img._getexif()
        
        if exif_data:
            for tag_id, value in exif_data.items():
                tag = TAGS.get(tag_id, tag_id)
                
                if tag == 'GPSInfo':
                    metadata['has_gps'] = True
                    metadata['location_risk'] = RISK_WEIGHTS['location_exif']
                
                if tag in ['DateTime', 'DateTimeOriginal', 'DateTimeDigitized']:
                    metadata['has_datetime'] = True
                
                if tag in ['Make', 'Model']:
                    metadata['camera_info'] = True
    
    except Exception as e:
        logger.debug(f"EXIF ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}")
    
    return metadata

def analyze_text(text: str) -> Dict:
    """í…ìŠ¤íŠ¸ ë¶„ì„ í•¨ìˆ˜ (í™•ì¥ë¨)"""
    detected_items = []
    total_risk = 0
    
    for pattern_name, pattern in PATTERNS.items():
        matches = re.findall(pattern, text)
        if matches:
            count = len(matches)
            risk = RISK_WEIGHTS.get(pattern_name, 10) * min(count, 3)
            total_risk += risk
            
            # ì˜ˆì œë¥¼ ë§ˆìŠ¤í‚¹ ì²˜ë¦¬
            masked_examples = []
            for match in matches[:2]:
                if isinstance(match, tuple):
                    match = ''.join(match)
                if pattern_name in ['phone', 'email', 'card', 'account', 'rrn', 'passport', 'driver_license']:
                    # ë” ê°•ë ¥í•œ ë§ˆìŠ¤í‚¹
                    if len(match) > 6:
                        masked = match[:3] + '*' * (len(match) - 6) + match[-3:]
                    else:
                        masked = '*' * len(match)
                else:
                    masked = match[:2] + '*' * (len(match) - 2)
                masked_examples.append(masked)
            
            detected_items.append({
                'type': pattern_name,
                'count': count,
                'risk_contribution': risk,
                'examples': masked_examples
            })
    
    return {
        'detected_items': detected_items,
        'total_risk': min(total_risk, 100)
    }

def detect_pharmacy_bag(image: np.ndarray, extracted_text: str) -> Dict:
    """ì•½ë´‰íˆ¬/ì²˜ë°©ì „ ê°ì§€"""
    pharmacy_info = {
        'detected': False,
        'type': None,
        'risk': 0,
        'features_found': []
    }
    
    # ì•½êµ­ ê´€ë ¨ í‚¤ì›Œë“œ
    pharmacy_keywords = [
        'ì•½êµ­', 'ì¡°ì œ', 'ì²˜ë°©', 'ë³µìš©', 'íˆ¬ì•½', 'ìš©ë²•', 'ìš©ëŸ‰',
        'pharmacy', 'ì •', 'ìº¡ìŠ', 'ì•Œ', 'mg', 'ml',
        'í™˜ìëª…', 'ì²˜ë°©ì˜', 'ì¡°ì œì¼', 'ì•½ì‚¬'
    ]
    
    keyword_matches = sum(1 for keyword in pharmacy_keywords if keyword in extracted_text)
    
    if keyword_matches >= 2:
        pharmacy_info['detected'] = True
        pharmacy_info['type'] = 'ì•½ë´‰íˆ¬/ì²˜ë°©ì „'
        pharmacy_info['risk'] = RISK_WEIGHTS['pharmacy_bag']
        pharmacy_info['features_found'].append(f'{keyword_matches}ê°œ ì•½êµ­ í‚¤ì›Œë“œ')
    
    # ë‚ ì§œ íŒ¨í„´ (ì¡°ì œì¼ì)
    date_patterns = [
        r'\d{4}[ë…„\.\-/]\d{1,2}[ì›”\.\-/]\d{1,2}',
        r'\d{4}-\d{2}-\d{2}',
        r'\d{2}/\d{2}/\d{4}'
    ]
    
    for pattern in date_patterns:
        if re.search(pattern, extracted_text):
            pharmacy_info['features_found'].append('ì¡°ì œ ë‚ ì§œ')
            break
    
    # ìš©ëŸ‰ í‘œì‹œ (mg, ml ë“±)
    dosage_pattern = r'\d+\s*(mg|ml|ì •|ìº¡ìŠ|ì•Œ|íšŒ)'
    if re.search(dosage_pattern, extracted_text):
        pharmacy_info['features_found'].append('ì•½ë¬¼ ìš©ëŸ‰ ì •ë³´')
    
    # ì´ë¦„ íŒ¨í„´
    name_pattern = r'[ê°€-í£]{2,4}(?:ë‹˜|ì”¨|í™˜ì)?'
    if re.search(name_pattern, extracted_text) and pharmacy_info['detected']:
        pharmacy_info['features_found'].append('í™˜ìëª…')
    
    # ì¶©ë¶„í•œ íŠ¹ì§•ì´ ë°œê²¬ë˜ë©´ í™•ì •
    if len(pharmacy_info['features_found']) >= 2 and pharmacy_info['detected']:
        if not pharmacy_info['risk']:
            pharmacy_info['risk'] = RISK_WEIGHTS['pharmacy_bag']
    else:
        pharmacy_info['detected'] = False
    
    return pharmacy_info

def detect_background_info(image: np.ndarray, ocr_results: list) -> Dict:
    """ë°°ê²½ ì •ë³´ ë¶„ì„ (ê°„íŒ, í‘œì§€íŒ ë“±)"""
    background_risks = {
        'detected': False,
        'types': [],
        'risk': 0
    }
    
    # OCR ê²°ê³¼ì—ì„œ ë°°ê²½ ì •ë³´ í‚¤ì›Œë“œ ê²€ìƒ‰
    background_keywords = [
        'ê°„íŒ', 'ë³‘ì›', 'í•™êµ', 'ì€í–‰', 'ë§ˆíŠ¸', 'ì•„íŒŒíŠ¸', 
        'ë¹Œë”©', 'ì—­', 'ì •ë¥˜ì¥', 'Hospital', 'School', 'Bank'
    ]
    
    extracted_text = ' '.join([text[1] for text in ocr_results])
    
    for keyword in background_keywords:
        if keyword in extracted_text:
            background_risks['detected'] = True
            background_risks['types'].append(keyword)
    
    if background_risks['detected']:
        background_risks['risk'] = RISK_WEIGHTS['background_info']
    
    return background_risks

def analyze_image_composition(image: np.ndarray) -> Dict:
    """ì´ë¯¸ì§€ êµ¬ë„ ë¶„ì„"""
    composition = {
        'has_people': False,
        'crowd_level': 'none',
        'indoor_outdoor': 'unknown',
        'brightness': 0
    }
    
    # ë°ê¸° ë¶„ì„
    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    composition['brightness'] = np.mean(gray)
    
    # ìƒ‰ìƒ ë¶„ì„ìœ¼ë¡œ ì‹¤ë‚´/ì™¸ ì¶”ì •
    hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)
    avg_saturation = np.mean(hsv[:, :, 1])
    
    if avg_saturation > 80:
        composition['indoor_outdoor'] = 'outdoor'
    else:
        composition['indoor_outdoor'] = 'indoor'
    
    return composition

def analyze_image(image_bytes: bytes) -> Dict:
    """ì´ë¯¸ì§€ ë¶„ì„ í•¨ìˆ˜ (ëŒ€í­ í™•ì¥ë¨)"""
    detected_items = []
    total_risk = 0
    detailed_analysis = {}
    
    try:
        # ì´ë¯¸ì§€ ë””ì½”ë”©
        nparr = np.frombuffer(image_bytes, np.uint8)
        image = cv2.imdecode(nparr, cv2.IMREAD_COLOR)
        if image is None:
             raise ValueError("ì´ë¯¸ì§€ ë””ì½”ë”© ì‹¤íŒ¨")
        rgb_image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        
        # 1. EXIF ë©”íƒ€ë°ì´í„° ë¶„ì„
        metadata = extract_exif_data(image_bytes)
        if metadata['has_gps']:
            total_risk += metadata['location_risk']
            detected_items.append({
                'type': 'location_exif',
                'count': 1,
                'risk_contribution': metadata['location_risk'],
                'description': 'GPS ìœ„ì¹˜ ì •ë³´ê°€ ì´ë¯¸ì§€ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤'
            })
        
        if metadata['has_datetime'] or metadata['camera_info']:
            risk = RISK_WEIGHTS['metadata']
            total_risk += risk
            detected_items.append({
                'type': 'metadata',
                'count': 1,
                'risk_contribution': risk,
                'description': 'ì¹´ë©”ë¼ ì •ë³´ ë° ì´¬ì˜ ì‹œê°„ì´ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤'
            })
        
        detailed_analysis['metadata'] = metadata
        
        # 2. ì–¼êµ´ íƒì§€ (ê°œì„ )
        face_results = face_detection.process(rgb_image)
        if face_results.detections:
            face_quality = detect_face_quality(image, face_results.detections)
            face_count = face_quality['total_faces']
            
            # ì„ ëª…í•œ ì–¼êµ´ì— ëŒ€í•œ ë†’ì€ ìœ„í—˜ë„
            if face_quality['clear_faces'] > 0:
                risk = RISK_WEIGHTS['face_clear'] * min(face_quality['clear_faces'], 3)
                total_risk += risk
                detected_items.append({
                    'type': 'face_clear',
                    'count': face_quality['clear_faces'],
                    'risk_contribution': risk,
                    'description': f'{face_quality["clear_faces"]}ê°œì˜ ì„ ëª…í•œ ì–¼êµ´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤'
                })
            
            # ì¼ë°˜ ì–¼êµ´ ìœ„í—˜ë„
            remaining_faces = face_count - face_quality['clear_faces']
            if remaining_faces > 0:
                risk = RISK_WEIGHTS['face'] * min(remaining_faces, 3)
                total_risk += risk
                detected_items.append({
                    'type': 'face',
                    'count': remaining_faces,
                    'risk_contribution': risk,
                    'description': f'{remaining_faces}ê°œì˜ ì–¼êµ´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤'
                })
            
            detailed_analysis['face_quality'] = face_quality
        
        # 3. ì–¼êµ´ ëœë“œë§ˆí¬ ë¶„ì„ (ì •ë°€ë„ í–¥ìƒ)
        face_mesh_results = face_mesh.process(rgb_image)
        if face_mesh_results.multi_face_landmarks:
            detailed_analysis['face_landmarks_detected'] = len(face_mesh_results.multi_face_landmarks)
        
        # 4. ì‹ ì²´ íƒì§€
        pose_results = pose_detection.process(rgb_image)
        if pose_results.pose_landmarks:
            risk = RISK_WEIGHTS['body']
            total_risk += risk
            detected_items.append({
                'type': 'body',
                'count': 1,
                'risk_contribution': risk,
                'description': 'ì‹ ì²´ ë¶€ìœ„ê°€ ëª…í™•í•˜ê²Œ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤'
            })
            detailed_analysis['body_detected'] = True
        
        # 5. ì† íƒì§€
        hands_results = hands_detection.process(rgb_image)
        if hands_results.multi_hand_landmarks:
            hand_count = len(hands_results.multi_hand_landmarks)
            risk = RISK_WEIGHTS['hands'] * min(hand_count, 2)
            total_risk += risk
            detected_items.append({
                'type': 'hands',
                'count': hand_count,
                'risk_contribution': risk,
                'description': f'{hand_count}ê°œì˜ ì†ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤ (ì§€ë¬¸ ë…¸ì¶œ ê°€ëŠ¥)'
            })
        
        # 6. OCRì„ í†µí•œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (í–¥ìƒëœ ë°©ì‹)
        all_ocr_texts = extract_text_enhanced(image_bytes)
        extracted_text = all_ocr_texts['combined_text']
        
        # 7. ì‹ ë¶„ì¦ ê°ì§€ (ê°•í™”ëœ ë¡œì§)
        id_card_result = detect_id_card(image, all_ocr_texts, face_results)
        if id_card_result['detected']:
            total_risk += id_card_result['risk']
            detected_items.append({
                'type': 'id_card',
                'count': 1,
                'risk_contribution': id_card_result['risk'],
                'description': f"âš ï¸ {id_card_result['type'] or 'ì‹ ë¶„ì¦'}ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤ (ì‹ ë¢°ë„: {id_card_result['confidence']:.0%})",
                'features': id_card_result['features_found']
            })
            detailed_analysis['id_card'] = id_card_result
        
        # 8. ì•½ë´‰íˆ¬/ì²˜ë°©ì „ ê°ì§€
        pharmacy_result = detect_pharmacy_bag(image, extracted_text)
        if pharmacy_result['detected']:
            total_risk += pharmacy_result['risk']
            detected_items.append({
                'type': 'pharmacy_bag',
                'count': 1,
                'risk_contribution': pharmacy_result['risk'],
                'description': f"âš ï¸ {pharmacy_result['type']}ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤ (ë¯¼ê°í•œ ì˜ë£Œì •ë³´ í¬í•¨)",
                'features': pharmacy_result['features_found']
            })
            detailed_analysis['pharmacy'] = pharmacy_result
        
        # 9. ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ê°œì¸ì •ë³´ íŒ¨í„´ ê²€ìƒ‰
        if extracted_text:
            # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ì—ì„œ ê°œì¸ì •ë³´ íŒ¨í„´ ê²€ìƒ‰
            text_analysis = analyze_text(extracted_text)
            if text_analysis['detected_items']:
                for item in text_analysis['detected_items']:
                    item['source'] = 'image_text'
                    # ì‹ ë¶„ì¦ ê°ì§€ì—ì„œ ì´ë¯¸ ìœ„í—˜ ì ìˆ˜ê°€ ë°˜ì˜ëœ ê²½ìš°, ì¤‘ë³µ ë°˜ì˜ ë°©ì§€
                    if item['type'] not in ['rrn', 'driver_license', 'passport_mrz', 'id_card_keywords']:
                         detected_items.append(item)
                         total_risk += item['risk_contribution']
                    elif not id_card_result['detected']:
                         # ì‹ ë¶„ì¦ìœ¼ë¡œ í™•ì •ë˜ì§€ ì•Šì€ ê²½ìš°ì—ë§Œ ê°œë³„ íŒ¨í„´ ì ìˆ˜ ë°˜ì˜
                         detected_items.append(item)
                         total_risk += item['risk_contribution']
            
            # ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ê°€ ë°œê²¬ëœ ê²ƒ ìì²´ë„ ìœ„í—˜ ìš”ì†Œ
            risk = RISK_WEIGHTS['text_in_image']
            total_risk += risk
            
            # ì¶”ì¶œëœ í…ìŠ¤íŠ¸ ìƒ˜í”Œ ì €ì¥
            text_sample = extracted_text[:100].replace('\n', ' ') + '...' if len(extracted_text) > 100 else extracted_text.replace('\n', ' ')
            
            detected_items.append({
                'type': 'text_in_image',
                'count': len(extracted_text.split()),
                'risk_contribution': risk,
                'description': f'ì´ë¯¸ì§€ì—ì„œ í…ìŠ¤íŠ¸ê°€ ì¶”ì¶œë˜ì—ˆìŠµë‹ˆë‹¤',
                'extracted_sample': text_sample
            })
            
            detailed_analysis['extracted_text'] = {
                'full_text': extracted_text,
                'length': len(extracted_text)
            }
        
        # 10. ë°°ê²½ ì •ë³´ ë¶„ì„ (EasyOCR ê²°ê³¼ë¥¼ ë‹¤ì‹œ ì‚¬ìš©)
        initial_ocr_results = reader.readtext(image_bytes) # ì •í™•í•œ bboxë¥¼ ìœ„í•´ ì´ˆê¸° OCR ê²°ê³¼ë¥¼ ì‚¬ìš©
        background_info = detect_background_info(image, initial_ocr_results)
        if background_info['detected']:
            total_risk += background_info['risk']
            detected_items.append({
                'type': 'background_info',
                'count': len(background_info['types']),
                'risk_contribution': background_info['risk'],
                'description': f'ë°°ê²½ì—ì„œ ìœ„ì¹˜ íŠ¹ì • ê°€ëŠ¥í•œ ì •ë³´ ë°œê²¬: {", ".join(background_info["types"][:3])}'
            })
        
        detailed_analysis['background_info'] = background_info
        
        # 11. ì´ë¯¸ì§€ êµ¬ë„ ë¶„ì„
        composition = analyze_image_composition(image)
        detailed_analysis['composition'] = composition
        
        # 12. ì´ë¯¸ì§€ í’ˆì§ˆ ë° í•´ìƒë„ ë¶„ì„
        h, w = image.shape[:2]
        detailed_analysis['resolution'] = {'width': w, 'height': h}
        detailed_analysis['high_resolution'] = w > 1920 or h > 1080
        
        if detailed_analysis['high_resolution']:
            total_risk += 5  # ê³ í•´ìƒë„ëŠ” ë” ë§ì€ ì •ë³´ ë…¸ì¶œ
    
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        return {'detected_items': [], 'total_risk': 0, 'detailed_analysis': {}}
    
    return {
        'detected_items': detected_items,
        'total_risk': min(total_risk, 100),
        'detailed_analysis': detailed_analysis
    }

def generate_personalized_feedback(detected_items: List[Dict], 
                                   combination_risks: List[Dict],
                                   user_context: Optional[Dict] = None) -> str:
    """ê·œì¹™ ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• í”¼ë“œë°± ìƒì„±"""
    
    # ìœ„í—˜ ìœ í˜•ë³„ ì¹´ìš´íŠ¸
    risk_types = Counter([item['type'] for item in detected_items])
    total_risk = sum([item['risk_contribution'] for item in detected_items])
    
    feedback_parts = []
    
    # 1. ì „ë°˜ì ì¸ ìœ„í—˜ë„ í‰ê°€
    if total_risk >= 70:
        feedback_parts.append("âš ï¸ ë§¤ìš° ìœ„í—˜í•œ ìˆ˜ì¤€ì˜ ê°œì¸ì •ë³´ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì¡°ì¹˜í•˜ì„¸ìš”.")
    elif total_risk >= 50:
        feedback_parts.append("âš¡ ì£¼ì˜ê°€ í•„ìš”í•œ ìˆ˜ì¤€ì˜ ê°œì¸ì •ë³´ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ë¯¼ê° ì •ë³´ë¥¼ ê°€ë ¤ì£¼ì„¸ìš”.")
    elif total_risk >= 30:
        feedback_parts.append("ğŸ’¡ ì¼ë¶€ ê°œì¸ì •ë³´ê°€ ë…¸ì¶œë˜ì–´ ìˆì–´ ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    else:
        feedback_parts.append("âœ… ê°œì¸ì •ë³´ ë…¸ì¶œ ìœ„í—˜ì´ ë¹„êµì  ë‚®ìŠµë‹ˆë‹¤. ê³„ì† ì£¼ì˜í•˜ì„¸ìš”.")
    
    # 2. ì£¼ìš” ìœ„í—˜ ìš”ì†Œ ê°•ì¡°
    high_risk_items = [
        ('id_card', 'ì‹ ë¶„ì¦ (ì£¼ë¯¼ë“±ë¡ì¦/ë©´í—ˆì¦/ì—¬ê¶Œ)'),
        ('rrn', 'ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸'),
        ('card', 'ì¹´ë“œë²ˆí˜¸/ê³„ì¢Œë²ˆí˜¸'),
        ('face_clear', 'ì„ ëª…í•œ ì–¼êµ´'),
        ('location_exif', 'GPS ìœ„ì¹˜'),
    ]
    
    critical_items = [name for type_key, name in high_risk_items if type_key in risk_types]
    if critical_items:
        feedback_parts.append(f"ê°€ì¥ ì‹¬ê°í•œ ìœ„í—˜ì€ **{critical_items[0]}** ë…¸ì¶œì…ë‹ˆë‹¤. **ì ˆëŒ€ ê³µê°œí•´ì„œëŠ” ì•ˆ ë©ë‹ˆë‹¤.**")
    
    # 3. ì¡°í•© ìœ„í—˜ ê°•ì¡°
    if combination_risks:
        high_severity = [r for r in combination_risks if r.get('severity') == 'high']
        if high_severity:
            feedback_parts.append(f"âŒ {high_severity[0]['description']} ìœ„í—˜ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì—¬ëŸ¬ ì •ë³´ê°€ í•©ì³ì ¸ ìœ„í—˜ë„ê°€ ê·¹ëŒ€í™”ë©ë‹ˆë‹¤.")
    
    # 4. ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ ê¸°ë°˜ ì¡°ì–¸
    if user_context:
        age_group = user_context.get('age_group')
        activity_type = user_context.get('activity_type')
        
        if age_group in ['youth', 'teenager']:
            feedback_parts.append("ì²­ì†Œë…„ì˜ ê²½ìš° ê°œì¸ì •ë³´ê°€ ì•…ìš©ë  ìœ„í—˜ì´ ë” ë†’ìœ¼ë‹ˆ, ì˜¨ë¼ì¸ ê³µìœ ì— ë”ìš± ì‹ ì¤‘í•´ì•¼ í•©ë‹ˆë‹¤.")
        
        if activity_type == 'SNS':
             feedback_parts.append("SNSëŠ” ì „íŒŒ ì†ë„ê°€ ë¹ ë¦…ë‹ˆë‹¤. ê³µìœ í•˜ê¸° ì „ì— ë°˜ë“œì‹œ ë¯¼ê° ì •ë³´ë¥¼ ëª¨ìì´í¬ ì²˜ë¦¬í•˜ì„¸ìš”.")
    
    # 5. êµ¬ì²´ì ì¸ ê°œì„  ë°©ë²• ì œì•ˆ
    if 'face_clear' in risk_types or 'id_card' in risk_types:
        feedback_parts.append("ì–¼êµ´ê³¼ ì‹ ë¶„ì¦ì˜ ëª¨ë“  ë¯¼ê° ì •ë³´ëŠ” ëª¨ìì´í¬ ë˜ëŠ” ê²€ì€ìƒ‰ ë§ˆìŠ¤í‚¹ì´ í•„ìˆ˜ì…ë‹ˆë‹¤.")
    
    if any(key in risk_types for key in ['phone', 'address', 'workplace']):
        feedback_parts.append("ì—°ë½ì²˜, ì£¼ì†Œ, ì§ì¥ ë“±ì˜ ì •ë³´ëŠ” ìµœì†Œí•œ ë¶€ë¶„ì ìœ¼ë¡œ ê°€ë ¤ì•¼ í•©ë‹ˆë‹¤.")
    
    # í”¼ë“œë°± ì¡°í•©
    return " ".join(feedback_parts)

def analyze_combination_risks(detected_items: List[Dict]) -> List[Dict]:
    """ì¡°í•© ìœ„í—˜ ë¶„ì„"""
    combination_risks = []
    detected_types = set([item['type'] for item in detected_items])
    
    for combo_risk in COMBINATION_RISKS:
        pattern_match_count = sum(1 for pattern_type in combo_risk['pattern'] 
                                if pattern_type in detected_types)
        
        if pattern_match_count >= combo_risk['min_count']:
            matched_types = [t for t in combo_risk['pattern'] if t in detected_types]
            
            combination_risks.append({
                'name': combo_risk['name'],
                'matched_types': matched_types,
                'risk_multiplier': combo_risk['risk_multiplier'],
                'description': combo_risk['description'],
                'severity': 'high' if combo_risk['risk_multiplier'] >= 2.0 else 'medium'
            })
    
    return combination_risks

def get_risk_level(score: int) -> str:
    """ìœ„í—˜ë„ ë ˆë²¨ íŒì •"""
    if score >= 70:
        return "ë§¤ìš° ìœ„í—˜"
    elif score >= 50:
        return "ìœ„í—˜"
    elif score >= 30:
        return "ì£¼ì˜"
    elif score >= 10:
        return "ì–‘í˜¸"
    else:
        return "ì•ˆì „"

def generate_recommendations(detected_items: List[Dict], combination_risks: List[Dict]) -> List[str]:
    """ê°œì„  ê¶Œê³ ì‚¬í•­ ìƒì„±"""
    recommendations = []
    
    type_messages = {
        'phone': 'ì „í™”ë²ˆí˜¸ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë’·ìë¦¬ë¥¼ ê°€ë¦¬ê±°ë‚˜ ì‚­ì œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.',
        'email': 'ì´ë©”ì¼ ì£¼ì†Œê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìŠ¤íŒ¸ ë©”ì¼ì˜ ìœ„í—˜ì´ ìˆìœ¼ë‹ˆ ì£¼ì˜í•˜ì„¸ìš”.',
        'rrn': 'âš ï¸ ì£¼ë¯¼ë“±ë¡ë²ˆí˜¸ëŠ” ì ˆëŒ€ ê³µê°œí•˜ì§€ ë§ˆì„¸ìš”. ì¦‰ì‹œ ì‚­ì œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.',
        'address': 'ìƒì„¸ ì£¼ì†Œê°€ ë…¸ì¶œë˜ë©´ ìœ„ì¹˜ê°€ íŠ¹ì •ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤. ë™ ë‹¨ìœ„ê¹Œì§€ë§Œ ê³µê°œí•˜ì„¸ìš”.',
        'detailed_address': 'ë²ˆì§€ìˆ˜ì™€ í˜¸ìˆ˜ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì •í™•í•œ ìœ„ì¹˜ íŠ¹ì •ì´ ê°€ëŠ¥í•˜ë¯€ë¡œ ì‚­ì œí•˜ì„¸ìš”.',
        'school': 'í•™êµëª…ì´ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‹ ì› íŒŒì•…ì˜ ë‹¨ì„œê°€ ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'name': 'ì‹¤ëª…ì´ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë‹‰ë„¤ì„ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.',
        'card': 'âš ï¸ ì¹´ë“œë²ˆí˜¸ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê¸ˆìœµ ì‚¬ê¸°ì˜ ìœ„í—˜ì´ ìˆìœ¼ë‹ˆ ì¦‰ì‹œ ì‚­ì œí•˜ì„¸ìš”.',
        'account': 'âš ï¸ ê³„ì¢Œë²ˆí˜¸ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê¸ˆìœµ ì •ë³´ëŠ” ì ˆëŒ€ ê³µê°œí•˜ì§€ ë§ˆì„¸ìš”.',
        'face': 'ì–¼êµ´ì´ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ëª¨ìì´í¬ ì²˜ë¦¬ë‚˜ ìŠ¤í‹°ì»¤ë¡œ ê°€ë¦¬ëŠ” ê²ƒì„ ê¶Œì¥í•©ë‹ˆë‹¤.',
        'face_clear': 'âš ï¸ ì„ ëª…í•œ ì–¼êµ´ì´ ë…¸ì¶œë˜ì–´ ì–¼êµ´ ì¸ì‹ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤. ë°˜ë“œì‹œ ê°€ë ¤ì£¼ì„¸ìš”.',
        'body': 'ì‹ ì²´ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê°œì¸ ì‹ë³„ì´ ê°€ëŠ¥í•  ìˆ˜ ìˆìœ¼ë‹ˆ ì£¼ì˜í•˜ì„¸ìš”.',
        'hands': 'ì†ì´ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì§€ë¬¸ì´ë‚˜ íŠ¹ì§•ì ì¸ ë¶€ë¶„ì€ ê°€ë ¤ì£¼ì„¸ìš”.',
        'text_in_image': 'ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë¯¼ê°í•œ ì •ë³´ê°€ ì—†ëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.',
        'workplace': 'ì§ì¥ ì •ë³´ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê°œì¸ ì‹ ì› íŒŒì•…ì— í™œìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'birth_date': 'ìƒë…„ì›”ì¼ì´ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‹ ì› ë„ìš©ì— ì•…ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'age': 'ë‚˜ì´ ì •ë³´ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë‹¤ë¥¸ ì •ë³´ì™€ ì¡°í•©í•˜ì—¬ ì‹ ì› ì¶”ì •ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.',
        'car_number': 'ì°¨ëŸ‰ ë²ˆí˜¸ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê°œì¸ ì¶”ì ì— ì•…ìš©ë  ìˆ˜ ìˆìœ¼ë‹ˆ ê°€ë ¤ì£¼ì„¸ìš”.',
        'passport': 'âš ï¸ ì—¬ê¶Œ ë²ˆí˜¸ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ ì‚­ì œí•˜ì„¸ìš”.',
        'driver_license': 'âš ï¸ ìš´ì „ë©´í—ˆ ë²ˆí˜¸ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì‹ ë¶„ì¦ ì •ë³´ëŠ” ì ˆëŒ€ ê³µê°œí•˜ì§€ ë§ˆì„¸ìš”.',
        'sns_id': 'SNS ê³„ì •ì´ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. íƒ€ í”Œë«í¼ ì¶”ì ì´ ê°€ëŠ¥í•˜ë‹ˆ ì£¼ì˜í•˜ì„¸ìš”.',
        'ip_address': 'IP ì£¼ì†Œê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìœ„ì¹˜ ì¶”ì ì— ì•…ìš©ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤.',
        'medical_info': 'âš ï¸ ì˜ë£Œ ì •ë³´ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ë§¤ìš° ë¯¼ê°í•œ ì •ë³´ì´ë¯€ë¡œ ì‚­ì œí•˜ì„¸ìš”.',
        'financial_info': 'ê¸ˆìœµ ì •ë³´ê°€ ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì†Œë“ ì •ë³´ëŠ” ê³µê°œí•˜ì§€ ë§ˆì„¸ìš”.',
        'metadata': 'ì´ë¯¸ì§€ ë©”íƒ€ë°ì´í„°ê°€ í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´¬ì˜ ê¸°ê¸°ì™€ ì‹œê°„ ì •ë³´ë¥¼ ì‚­ì œí•˜ì„¸ìš”.',
        'location_exif': 'âš ï¸ GPS ìœ„ì¹˜ ì •ë³´ê°€ ì´ë¯¸ì§€ì— í¬í•¨ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì •í™•í•œ ìœ„ì¹˜ê°€ ë…¸ì¶œë©ë‹ˆë‹¤. ë©”íƒ€ë°ì´í„°ë¥¼ ì œê±°í•˜ì„¸ìš”.',
        'background_info': 'ë°°ê²½ì—ì„œ ìœ„ì¹˜ë¥¼ íŠ¹ì •í•  ìˆ˜ ìˆëŠ” ì •ë³´ê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ê°„íŒì´ë‚˜ í‘œì§€íŒì„ ê°€ë ¤ì£¼ì„¸ìš”.',
        'id_card': 'âš ï¸ ì‹ ë¶„ì¦ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ë¯¼ë“±ë¡ì¦, ë©´í—ˆì¦ ë“± ì‹ ë¶„ì¦ì€ ì ˆëŒ€ ê³µê°œí•˜ì§€ ë§ˆì„¸ìš”.',
        'pharmacy_bag': 'âš ï¸ ì•½ë´‰íˆ¬/ì²˜ë°©ì „ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. í™˜ìëª…, ë³‘ëª…, ì•½ë¬¼ ì •ë³´ëŠ” ë¯¼ê°í•œ ì˜ë£Œì •ë³´ì…ë‹ˆë‹¤. ì¦‰ì‹œ ì‚­ì œí•˜ì„¸ìš”.',
    }
    
    # ê¸°ë³¸ ê¶Œê³ ì‚¬í•­
    detected_types = set([item['type'] for item in detected_items])
    for item_type in detected_types:
        if item_type in type_messages:
            recommendations.append(type_messages[item_type])
    
    # ì¡°í•© ìœ„í—˜ ê¶Œê³ ì‚¬í•­
    for combo_risk in combination_risks:
        if combo_risk['severity'] == 'high':
            recommendations.append(f"âš ï¸ {combo_risk['description']} - ì¼ë¶€ ì •ë³´ë¥¼ ì‚­ì œí•˜ê±°ë‚˜ ê°€ë ¤ì£¼ì„¸ìš”.")
        else:
            recommendations.append(f"âš¡ {combo_risk['description']} - ì£¼ì˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")
    
    # ì¼ë°˜ ê¶Œê³ ì‚¬í•­ ì¶”ê°€
    if len(detected_items) > 5:
        recommendations.append('âš ï¸ ë‹¤ìˆ˜ì˜ ê°œì¸ì •ë³´ê°€ ë™ì‹œì— ë…¸ì¶œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì „ë°˜ì ì¸ ì¬ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤.')
    
    if not recommendations:
        recommendations.append('âœ… ê°œì¸ì •ë³´ ë…¸ì¶œ ìœ„í—˜ì´ ë‚®ìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ í•­ìƒ ì£¼ì˜í•˜ì„¸ìš”.')
    
    return recommendations

@app.get("/")
async def root():
    return {
        "message": "ê°œì¸ì •ë³´ ìœ„í—˜ ìê°€ ì§„ë‹¨ ì„œë¹„ìŠ¤ API (OpenCV ê¸°ë°˜)",
        "version": "2.1 (ì‹ ë¶„ì¦ ì¸ì‹ë¥  ê°œì„ )",
        "features": [
            "ê³ ê¸‰ ì–¼êµ´ ê°ì§€ ë° í’ˆì§ˆ ë¶„ì„",
            "EXIF GPS ìœ„ì¹˜ ì •ë³´ ì¶”ì¶œ",
            "ë°°ê²½ ì •ë³´ ë¶„ì„",
            "ì† ë° ì‹ ì²´ ë¶€ìœ„ ê°ì§€",
            "í™•ì¥ëœ ê°œì¸ì •ë³´ íŒ¨í„´ ì¸ì‹",
            "ì¡°í•© ìœ„í—˜ ë¶„ì„",
            "ì‹ ë¶„ì¦ ê°ì§€ ë¡œì§ ê°•í™” (ì ìˆ˜ ê¸°ë°˜, êµì°¨ ê²€ì¦)"
        ]
    }

@app.post("/analyze/text", response_model=AnalysisResponse)
async def analyze_text_endpoint(request: TextAnalysisRequest):
    """í…ìŠ¤íŠ¸ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        if not request.text:
            raise HTTPException(status_code=400, detail="í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤")
        
        analysis = analyze_text(request.text)
        combination_risks = analyze_combination_risks(analysis['detected_items'])
        
        # ì¡°í•© ìœ„í—˜ìœ¼ë¡œ ì¸í•œ ì¶”ê°€ ì ìˆ˜
        combo_bonus = sum(risk['risk_multiplier'] * 10 for risk in combination_risks)
        final_risk = min(analysis['total_risk'] + combo_bonus, 100)
        
        recommendations = generate_recommendations(analysis['detected_items'], combination_risks)
        risk_level = get_risk_level(final_risk)
        
        # ê·œì¹™ ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• í”¼ë“œë°± ìƒì„±
        personalized_feedback = generate_personalized_feedback(
            analysis['detected_items'], 
            combination_risks, 
            request.user_context
        )
        
        return AnalysisResponse(
            risk_score=int(final_risk),
            detected_items=analysis['detected_items'],
            combination_risks=combination_risks,
            recommendations=recommendations,
            personalized_feedback=personalized_feedback,
            risk_level=risk_level
        )
    
    except Exception as e:
        logger.error(f"í…ìŠ¤íŠ¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze/image", response_model=AnalysisResponse)
async def analyze_image_endpoint(file: UploadFile = File(...), user_context: str = None):
    """ì´ë¯¸ì§€ ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸"""
    try:
    
        if not file.content_type.startswith('image/'):
            raise HTTPException(status_code=400, detail="ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œ ê°€ëŠ¥í•©ë‹ˆë‹¤")
        
        contents = await file.read()
        analysis = analyze_image(contents)
        combination_risks = analyze_combination_risks(analysis['detected_items'])
        
        # ì¡°í•© ìœ„í—˜ìœ¼ë¡œ ì¸í•œ ì¶”ê°€ ì ìˆ˜
        combo_bonus = sum(risk['risk_multiplier'] * 10 for risk in combination_risks)
        final_risk = min(analysis['total_risk'] + combo_bonus, 100)
        
        recommendations = generate_recommendations(analysis['detected_items'], combination_risks)
        risk_level = get_risk_level(final_risk)
        
        # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ íŒŒì‹±
        context_dict = {}
        if user_context:
            try:
                import json
                context_dict = json.loads(user_context)
            except:
                context_dict = {'activity_type': user_context}
        
        # ê·œì¹™ ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• í”¼ë“œë°± ìƒì„±
        personalized_feedback = generate_personalized_feedback(
            analysis['detected_items'], 
            combination_risks, 
            context_dict
        )
        
        return AnalysisResponse(
            risk_score=int(final_risk),
            detected_items=analysis['detected_items'],
            combination_risks=combination_risks,
            recommendations=recommendations,
            personalized_feedback=personalized_feedback,
            risk_level=risk_level,
            detailed_analysis=analysis.get('detailed_analysis')
        )
    
    except Exception as e:
        logger.error(f"ì´ë¯¸ì§€ ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.post("/analyze/combined")
async def analyze_combined_endpoint(
    text: Optional[str] = None,
    file: Optional[UploadFile] = File(None),
    user_context: Optional[str] = None
):
    """í…ìŠ¤íŠ¸ì™€ ì´ë¯¸ì§€ í†µí•© ë¶„ì„ ì—”ë“œí¬ì¸íŠ¸"""
    try:
        total_risk = 0
        all_detected_items = []
        detailed_analysis = {}
        
        # í…ìŠ¤íŠ¸ ë¶„ì„
        if text:
            text_analysis = analyze_text(text)
            total_risk += text_analysis['total_risk']
            all_detected_items.extend(text_analysis['detected_items'])
        
        # ì´ë¯¸ì§€ ë¶„ì„
        if file:
            contents = await file.read()
            image_analysis = analyze_image(contents)
            total_risk += image_analysis['total_risk']
            all_detected_items.extend(image_analysis['detected_items'])
            detailed_analysis = image_analysis.get('detailed_analysis', {})
        
        # ì¡°í•© ìœ„í—˜ ë¶„ì„
        combination_risks = analyze_combination_risks(all_detected_items)
        combo_bonus = sum(risk['risk_multiplier'] * 10 for risk in combination_risks)
        final_risk = min(total_risk + combo_bonus, 100)
        
        recommendations = generate_recommendations(all_detected_items, combination_risks)
        risk_level = get_risk_level(final_risk)
        
        # ì‚¬ìš©ì ì»¨í…ìŠ¤íŠ¸ íŒŒì‹±
        context_dict = {}
        if user_context:
            try:
                import json
                context_dict = json.loads(user_context)
            except:
                context_dict = {'activity_type': user_context}
        
        # ê·œì¹™ ê¸°ë°˜ ê°œì¸ ë§ì¶¤í˜• í”¼ë“œë°± ìƒì„±
        personalized_feedback = generate_personalized_feedback(
            all_detected_items, 
            combination_risks, 
            context_dict
        )
        
        return AnalysisResponse(
            risk_score=int(final_risk),
            detected_items=all_detected_items,
            combination_risks=combination_risks,
            recommendations=recommendations,
            personalized_feedback=personalized_feedback,
            risk_level=risk_level,
            detailed_analysis=detailed_analysis
        )
    
    except Exception as e:
        logger.error(f"í†µí•© ë¶„ì„ ì˜¤ë¥˜: {str(e)}")
        raise HTTPException(status_code=500, detail=str(e))

@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "healthy",
        "timestamp": datetime.now().isoformat(),
        "services": {
            "face_detection": "active",
            "ocr": "active",
            "text_analysis": "active"
        }
    }

if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)